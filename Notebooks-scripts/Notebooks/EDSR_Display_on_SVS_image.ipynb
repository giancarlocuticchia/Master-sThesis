{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["4stogQLDsfHy","SWpxAapCrnsn","N9QzciRIr17b","lodMDN6yw3Ch"],"gpuType":"T4","authorship_tag":"ABX9TyP0C0BMpGRTOcWlZKaV52T2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["The code below will take as input a SVS image, and the user can provide a crop from this image so we can get:\n","* The original High-Resolution (HR) crop\n","* Bicubic upscaling of the Low-Resolution (LR) version of the crop\n","* Super-Resolution upscaling of the LR version of the crop from two different trained versions of the EDSR x4 model\n","* Corresponding values of MSE, PSNR and SSIM respect the upscalings and the original HR crop.\n","\n","The user must have beforehand:\n","1. A properly set EDSR-PyTorch repository.\n","2. The main_use.py file we made, and properly locate it in the src folder of the EDSR-PyTorch repository.\n","3. The SVS image to use (and provide the path ot its file).\n","4. The state dictionary files of the trained versions of the EDSRx4 model (and provide the path to the corresponding files).\n","5. Fill the corresponding variables in the code below when needed."],"metadata":{"id":"knjRUE3sqBTN"}},{"cell_type":"markdown","source":["We will use the directories:"],"metadata":{"id":"abgUF3Wmbgf8"}},{"cell_type":"code","source":["import os\n","\n","dir_base = os.getcwd()\n","dir_edsrpytorch = os.path.join(dir_base,\"EDSR-PyTorch\")     # ./EDSR-PyTorch\n","dir_src = os.path.join(dir_edsrpytorch,\"src\")               # ./EDSR-PyTorch/src\n","dir_pretrain = os.path.join(dir_edsrpytorch, \"pre-train\")   # ./EDSR-PyTorch/pre-train\n","dir_images = os.path.join(dir_base,\"images\")                # ./images"],"metadata":{"id":"b5t4LlAlbd91","executionInfo":{"status":"ok","timestamp":1716139011393,"user_tz":-120,"elapsed":3,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["We will also require to use the OpenSlide library, so the user must have it installed before. We can do it in Google Colab with the code:"],"metadata":{"id":"NCBdOaC-tCTh"}},{"cell_type":"code","source":["try:\n","  import openslide\n","except:\n","  !apt update && apt install -y openslide-tools\n","  !pip install openslide-python\n","  import openslide"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFwZvoZctJf5","executionInfo":{"status":"ok","timestamp":1716139042746,"user_tz":-120,"elapsed":29375,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}},"outputId":"b35e43cb-50d5-46e7-fe44-64f290840d59"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n","Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,118 kB]\n","Fetched 2,351 kB in 4s (575 kB/s)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  libopenslide0\n","Suggested packages:\n","  libtiff-tools\n","The following NEW packages will be installed:\n","  libopenslide0 openslide-tools\n","0 upgraded, 2 newly installed, 0 to remove and 45 not upgraded.\n","Need to get 104 kB of archives.\n","After this operation, 297 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopenslide0 amd64 3.4.1+dfsg-5build1 [89.8 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 openslide-tools amd64 3.4.1+dfsg-5build1 [13.8 kB]\n","Fetched 104 kB in 2s (50.8 kB/s)\n","Selecting previously unselected package libopenslide0.\n","(Reading database ... 121918 files and directories currently installed.)\n","Preparing to unpack .../libopenslide0_3.4.1+dfsg-5build1_amd64.deb ...\n","Unpacking libopenslide0 (3.4.1+dfsg-5build1) ...\n","Selecting previously unselected package openslide-tools.\n","Preparing to unpack .../openslide-tools_3.4.1+dfsg-5build1_amd64.deb ...\n","Unpacking openslide-tools (3.4.1+dfsg-5build1) ...\n","Setting up libopenslide0 (3.4.1+dfsg-5build1) ...\n","Setting up openslide-tools (3.4.1+dfsg-5build1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","Collecting openslide-python\n","  Downloading openslide-python-1.3.1.tar.gz (358 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m359.0/359.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from openslide-python) (9.4.0)\n","Building wheels for collected packages: openslide-python\n","  Building wheel for openslide-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openslide-python: filename=openslide_python-1.3.1-cp310-cp310-linux_x86_64.whl size=33548 sha256=4f82e17aca5f33eda6191ce6c044f5862ba12362ec6c32e30fd8dc9f5429f889\n","  Stored in directory: /root/.cache/pip/wheels/79/79/fa/29a0087493c69dff7fd0b70fab5d6771002a531010161d2d97\n","Successfully built openslide-python\n","Installing collected packages: openslide-python\n","Successfully installed openslide-python-1.3.1\n"]}]},{"cell_type":"markdown","source":["# 1. Getting the repository"],"metadata":{"id":"L-G8LbpGhsf2"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kKV_ouE-gqtY","executionInfo":{"status":"ok","timestamp":1716139052699,"user_tz":-120,"elapsed":6435,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}},"outputId":"f7e3ac8f-ff06-4377-8eb4-5d99bdaae83d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into '/content/EDSR-PyTorch'...\n","remote: Enumerating objects: 806, done.\u001b[K\n","remote: Total 806 (delta 0), reused 0 (delta 0), pack-reused 806\u001b[K\n","Receiving objects: 100% (806/806), 63.09 MiB | 13.42 MiB/s, done.\n","Resolving deltas: 100% (516/516), done.\n"]}],"source":["# Cloning the repository as instructed in https://github.com/sanghyun-son/EDSR-PyTorch\n","!git clone https://github.com/thstkdgus35/EDSR-PyTorch {dir_edsrpytorch}"]},{"cell_type":"markdown","source":["# 2. Get the main_use.py file"],"metadata":{"id":"4stogQLDsfHy"}},{"cell_type":"markdown","source":["The user must download it beforehand and place it inside of the src folder of the EDSR-PyTorch repository."],"metadata":{"id":"vJHRLFmSsko0"}},{"cell_type":"markdown","source":["# 3. Get the SVS image"],"metadata":{"id":"SWpxAapCrnsn"}},{"cell_type":"markdown","source":["The user must download it beforehand and place it inside of the dir_images folder."],"metadata":{"id":"Q4iOGs50rroP"}},{"cell_type":"markdown","source":["# 4. Get the pretrained models"],"metadata":{"id":"N9QzciRIr17b"}},{"cell_type":"markdown","source":["The user must download them beforehand and place them inside of the dir_pretrain folder. We can also get the pretrained EDSR x4 model from its authors with the code below."],"metadata":{"id":"jHnA7P4gr5YW"}},{"cell_type":"code","source":["import os\n","import urllib.request\n","\n","# Pre-train folder\n","if not os.path.exists(dir_pretrain):\n","    os.makedirs(dir_pretrain, exist_ok=True)\n","\n","# Pretrained model\n","pretrain_model = \"edsr_x4-4f62e9ef.pt\"\n","pretrain_model_path = os.path.join(dir_pretrain, pretrain_model)\n","\n","# Download it if not present\n","if not os.path.isfile(pretrain_model_path):\n","  url = \"https://cv.snu.ac.kr/research/EDSR/models/edsr_x4-4f62e9ef.pt\"\n","  with urllib.request.urlopen(url) as response, open(pretrain_model_path, 'wb') as out_file:\n","    data = response.read()\n","    out_file.write(data)\n","  print(f\"Pretrained model {pretrain_model} has been downloaded inside {dir_pretrain}\")\n","else :\n","  print(f\"Using pretrained model {pretrain_model_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IM0ns8qmiDoZ","executionInfo":{"status":"ok","timestamp":1716136807408,"user_tz":-120,"elapsed":32961,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}},"outputId":"235b410a-2487-4d7f-ac02-b2ab51ec15a6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Pretrained model edsr_x4-4f62e9ef.pt has been downloaded inside /content/EDSR-PyTorch/pre-train\n"]}]},{"cell_type":"markdown","source":["# 5. Displaying of the SVS image"],"metadata":{"id":"YtSo1P7etXqL"}},{"cell_type":"markdown","source":["The final image will be saved as comp_name in the folder provided in path_to_save."],"metadata":{"id":"g62iRZk96SDy"}},{"cell_type":"markdown","source":["## 5.1 Functions definitions"],"metadata":{"id":"lodMDN6yw3Ch"}},{"cell_type":"code","source":["from PIL import Image, ImageDraw, ImageFont\n","from skimage.metrics import structural_similarity as skimage_ssim\n","import cv2\n","import math\n","import numpy as np\n","import os\n","\n","## Returns a list of paths for all the files with a certain extension inside a directory and its subdirectories\n","def get_filepaths(directory, file_extension=\"\"):\n","    files_list = []\n","    # Walk through the directory and its subdirectories\n","    for dir, subdirs, files in os.walk(directory):\n","        for file in files:\n","            # Check if the file has a the extension\n","            if file.endswith(file_extension):\n","                # Add the full path to the list\n","                files_list.append(os.path.join(dir, file))\n","\n","    return files_list\n","\n","\n","## Function to rescale image with text to fit into a vertical space.\n","def fit_image_to_space(image, vertical_space, image_text=\"\",\n","                       font=ImageFont.load_default()):\n","  # Determine text height\n","  draw_text = ImageDraw.Draw(image)\n","  text_height = draw_text.textbbox((0, 0), image_text, font)[3]\n","\n","  # Determine scale factor\n","  image_space = vertical_space - text_height\n","  image_width = image.size[0]\n","  image_height = image.size[1]\n","  scale_factor = image_space / image_height\n","\n","  # Rescale image\n","  new_image_width = math.floor(image_width * scale_factor)\n","  new_image_height = math.floor(image_height * scale_factor)\n","  new_image = image.resize((new_image_width, new_image_height), Image.BICUBIC)\n","\n","  return new_image\n","\n","\n","## Function to make a composition of images as described below.\n","def create_composition(base_image, export_path, images=[], images_text=[],\n","                       hist_image=None, rescale_hist=True,\n","                       font=ImageFont.load_default(), font_color=\"black\"):\n","  \"\"\"\n","  Will take a base image and place it to the left on a composition. Up to 4\n","  other images will be displayed to the right, on a 2x2 fashion (left to right,\n","  top to bottom), with their corresponding text below each. An histogram can\n","  be also displayed to the most right of the composition.\n","\n","  Will save the final composition image in \"export_path\", which is the absolute\n","  path to the filename of the desired image, including its file extension.\n","\n","  All images must be PIL images.\n","\n","  images and images_text must be each a list of the same length, of maximum length\n","  equal to 4. Each image on \"images\" must be of the same dimensions. Each text on\n","  \"images_text\" must have the same number of lines.\n","  \"\"\"\n","\n","  # Get the size of the base image\n","  base_size = base_image.size\n","\n","  # Get the size of the histogram image\n","  if hist_image :\n","    # Rescale histogram if desired\n","    if rescale_hist :\n","      hist_size = hist_image.size\n","      new_hist_height = base_size[1]\n","      new_hist_width = math.floor(hist_size[0] * base_size[1] / hist_size[1])\n","      hist_image = hist_image.resize((new_hist_width, new_hist_height), Image.BICUBIC)\n","\n","    hist_size = hist_image.size\n","  else :\n","    hist_size = (0,0)\n","\n","  # Get canvas height\n","  canvas_height = max(base_size[1], hist_size[1])\n","\n","  # If there are internal images, get their size\n","  if images :\n","    # Make a list for the new rescaled images\n","    new_images = []\n","    # Rescale internal images\n","    for index, image in enumerate(images) :\n","      new_images.append(fit_image_to_space(image=image,\n","                                           vertical_space = canvas_height // 2,\n","                                           image_text=images_text[index],\n","                                           font=font) )\n","    # Get sizes\n","    images_size = new_images[0].size\n","  else:\n","    images_size = (0,0)\n","\n","  # Get canvas width\n","  canvas_width = base_size[0] + 2*images_size[0] + hist_size[0]  # without margins\n","  # Define internal margins\n","  margins_proportions = 0.01\n","  margin_size = math.ceil(margins_proportions * canvas_width)\n","  # Get canvas width with margins\n","  if images: canvas_width += 2*margin_size\n","  if hist_image: canvas_width += margin_size\n","\n","  # Create a new image for the composition\n","  composition_size = (canvas_width, canvas_height)\n","  composition = Image.new(\"RGB\", composition_size, \"white\")\n","\n","  # Define coordinates to paste the images\n","  current_horizontal = 0\n","  current_vertical = 0\n","\n","  # Paste base image\n","  composition.paste(base_image, (current_horizontal, current_vertical))\n","\n","  # Paste internal images and write their text, if any\n","  if images:\n","    current_horizontal = base_size[0] + margin_size\n","    current_vertical = 0\n","      # Define the internal positions\n","    internal_positions = [\n","        [current_horizontal, current_vertical],\n","        [current_horizontal + images_size[0] + margin_size, current_vertical],\n","        [current_horizontal, current_vertical + canvas_height // 2],\n","        [current_horizontal + images_size[0] + margin_size, current_vertical + canvas_height // 2]\n","    ]\n","      # Write draw text object\n","    draw_text = ImageDraw.Draw(composition)\n","    for index in range(len(images)):\n","      # Paste image\n","      composition.paste(new_images[index], (internal_positions[index][0], internal_positions[index][1]))\n","      # Write text\n","      text_width = draw_text.textbbox((0, 0), images_text[index], font)[2]\n","      text_position = (internal_positions[index][0] + (images_size[0] - text_width) // 2,\n","                      internal_positions[index][1] + images_size[1])\n","      draw_text.text(text_position, images_text[index], fill=font_color, font=font, align=\"center\")\n","\n","  # Paste histogram image, if any\n","  if hist_image :\n","    current_horizontal = base_size[0] + margin_size\n","    if images: current_horizontal += 2*(images_size[0]+margin_size)\n","    current_vertical = 0\n","\n","    composition.paste(hist_image, (current_horizontal, current_vertical))\n","\n","  # Save the final composition image\n","  composition.save(export_path)\n","\n","\n","## Getting left image for the composition\n","def get_base_image(slide, width=1000, level=\"\"):\n","  # Define level\n","  if not level:\n","    level = slide.level_count - 1\n","  # Define location and size\n","  location = (0,0)\n","  size = slide.level_dimensions[level]\n","  # Read image\n","  image = slide.read_region(location, level, size)\n","  # Rescale image to desired width\n","  height = width * size[1] // size[0]\n","  image = image.resize((width, height), Image.BICUBIC)\n","\n","  return image\n","\n","## Getting crop of original image for the composition\n","def get_original_crop(slide, start_relative=(0.0,0.0), crop_size=(1,1), level=0,\n","                      DesiredMagnification=20.0):\n","  # Get rescaling factor depending on Magnification\n","  ApparentMagnification = int(slide.properties[\"aperio.AppMag\"])\n","  MagnificationRatio = max(ApparentMagnification/DesiredMagnification,1.0)    #It's 1 in case the Desired one is bigger than the maximum available\n","\n","  # Get crop dimensions\n","  crop_width = math.floor(crop_size[0] * MagnificationRatio)\n","  crop_height = math.floor(crop_size[1] * MagnificationRatio)\n","\n","  # Get crop starting position (relative must be from 0 to 1)\n","  image_size = slide.level_dimensions[level]\n","  start_x = math.floor(image_size[0] * start_relative[0])\n","  start_y = math.floor(image_size[1] * start_relative[1])\n","  start_point = (start_x, start_y)\n","\n","  # Read image\n","  image = slide.read_region(start_point, level, (crop_width, crop_height))\n","\n","  # Rescale image to desired size if needed\n","  if MagnificationRatio > 1.0 :\n","    image = image.resize(crop_size, Image.BICUBIC)\n","    new_width = image_size[0] // MagnificationRatio\n","    new_height = image_size[1] // MagnificationRatio\n","    image_size = (new_width,new_height)\n","\n","  return image, image_size\n","\n","\n","## Bicubic upscaling of a PIL image\n","def get_bicubic_image(image, scale=1):\n","  width, height = image.size\n","  width = width * scale\n","  height = height * scale\n","  new_image = image.resize((width, height), Image.BICUBIC)\n","  return new_image\n","\n","\n","## Convert PIL image to array (by saving and loading)\n","def image_to_array(image, temp_folder=\"\", keep_on_disk=False):\n","  \"\"\"\n","  Function to start with a PIL Image and get its equivalent array.\n","\n","  This reason of making this function like this, is that when doing it with:\n","\n","    image_array = np.array(image_PIL)\n","\n","  We were getting discrepancies of values while measuring PSNR. I.e., an\n","  image_array like above would get a PSNR different from the image_array\n","  defined below. The latter is then preferrable.\n","  \"\"\"\n","  # Get tem folder\n","  if not temp_folder :\n","    temp_folder = os.getcwd()\n","  # Save temp image\n","  image_name = \"temp_image_to_array.png\"\n","  file_path = os.path.join(temp_folder, image_name)\n","  image.save(file_path)\n","\n","  # Load temp image as array\n","  image_array = cv2.imread(file_path)\n","\n","  # Delete temp image\n","  if not keep_on_disk :\n","    try:\n","      # Attempt to remove the file\n","      os.remove(file_path)\n","    except OSError as e:\n","      # Handle errors, if any\n","      print(f\"Error: {e}\")\n","\n","  return image_array\n","\n","## Convert PIL image to array (by saving and loading)\n","def array_to_image(image_array, temp_folder=\"\", keep_on_disk=False):\n","  \"\"\"\n","  Function to start with an array and get its equivalent PIL Image,\n","  by saving it in disk and loading it.\n","  \"\"\"\n","  # Get tem folder\n","  if not temp_folder :\n","    temp_folder = os.getcwd()\n","  # Save temp array\n","  image_array_name = \"temp_array_to_image.png\"\n","  file_path = os.path.join(temp_folder, image_array_name)\n","  cv2.imwrite(file_path, image_array)\n","\n","  # Load temp image as array\n","  image = Image.open(file_path)\n","\n","  # Delete temp image\n","  if not keep_on_disk :\n","    try:\n","      # Attempt to remove the file\n","      os.remove(file_path)\n","    except OSError as e:\n","      # Handle errors, if any\n","      print(f\"Error: {e}\")\n","\n","  return image\n","\n","\n","## Mean Squared Error between two images\n","def calc_mse(imageA, imageB):\n","  \"\"\"\n","  'Mean Squared Error' between two images of same dimensions and type (RGB, for example)\n","\n","  Images must be an array (e.g. Array of iunt8 of shape (height,width,3))\n","\n","  MSE = sum over N of (Ai - Bi)^2 / N     where N is the number of pixels per image\n","\n","  Images are converted to float32 precision.\n","  \"\"\"\n","  imageA_float32 = imageA.astype(np.float32)\n","  imageB_float32 = imageB.astype(np.float32)\n","\n","  MSE = np.sum((imageA_float32 - imageB_float32)**2)\n","  MSE /= math.prod(imageA_float32.shape[dim] for dim in range(len(imageA_float32.shape)))\n","\n","  return MSE\n","\n","\n","## Peak-Signal-To-Noise Ratio between a SR and a HR image\n","def calc_psnr_simplified(sr, hr, scale, rgb_range=255, crop=True):\n","  \"\"\"\n","  Notes:\n","    * sr and hr must be a numpy array.\n","    * sr and hr are converted to float32 precision.\n","    * sr and hr might be cropped from their borders with a number \"shave\" of\n","    pixels, if crop=True.\n","  \"\"\"\n","  diff = (sr.astype(np.float32) - hr.astype(np.float32))  # Ensure float32 precision\n","  if crop :\n","    shave = scale + 6\n","    valid = diff[shave:-shave, shave:-shave, ...]         # Cropping out borders of the image\n","  else :\n","    valid = diff\n","  mse = np.mean(valid ** 2)\n","  psnr = -10 * math.log10(mse / (rgb_range ** 2))\n","\n","  return psnr\n","\n","## Structural Similarity between two images\n","def calc_ssim(imageA, imageB, channel_axis=2):\n","  \"\"\"\n","  'Structural Similarity' between two images, calculated with \"structural_similarity\"\n","  from the library skimage.metrics.\n","\n","  Images must be an array (e.g. Array of iunt8 of shape (height,width,3)) and\n","  are converted to float32 precision.\n","\n","  The argument channel_axis correspond to the index of the arrays corresponding\n","  to their color channels (typically 0 or 2).\n","  \"\"\"\n","  imageA_float32 = imageA.astype(np.float32)\n","  imageB_float32 = imageB.astype(np.float32)\n","\n","  SSIM = skimage_ssim(imageA_float32, imageB_float32, channel_axis=channel_axis)\n","\n","  return SSIM\n","\n","## Determine the MSE, PSNR OR SSIM of a list of images respect an original image\n","def make_measurements(image_original, images=[], measure=\"\", temp_folder=\"\"):\n","  # All images must be a numpy array of same shape (height, width, channels)\n","  if temp_folder == \"\":\n","    temp_folder = os.getcwd()\n","  img_original = image_to_array(image_original, temp_folder=temp_folder, keep_on_disk=False)\n","\n","  # Make measurements\n","  measurements = []\n","  for image in images :\n","    # Convert image to numpy array\n","    img = image_to_array(image, temp_folder=temp_folder, keep_on_disk=False)\n","    if measure == \"MSE\" :\n","      #Mean Squared Error\n","      try:\n","        MSE = calc_mse(img_original, img)\n","      except ValueError:\n","        MSE = \"\"\n","      measurements.append(MSE)\n","    elif measure == \"PSNR\":\n","      #Peak Signal-to-Noise Ratio\n","      try:\n","        PSNR = calc_psnr_simplified(img, img_original, scale, rgb_range=255, crop=True)\n","      except ValueError:\n","        PSNR = \"\"\n","      measurements.append(PSNR)\n","    elif measure == \"SSIM\":\n","      #Structural Similarity\n","      try:\n","        SSIM = calc_ssim(img_original, img, channel_axis=2)\n","      except ValueError:\n","        SSIM = \"\"\n","      measurements.append(SSIM)\n","    else :\n","      measurements.append(\"N/A\")\n","\n","  return measurements\n","\n","## Round values on a list or assign \"N/A\" if not possible\n","def round_values_in_list(list_values, decimals=2, na_value=\"N/A\"):\n","  new_list = []\n","  for value in list_values :\n","    try :\n","      val = f\"{round(value,decimals):.{decimals}f}\"\n","    except:\n","      val = na_value\n","    new_list.append(val)\n","\n","  return new_list\n","\n","\n","## Draw a rectangle inside an image (NOTE: this will modify the original image)\n","def draw_rectangle(image, start_relative=(0.0,0.0), dimensions=(1,1),\n","                   frame_color=\"red\", frame_width=1, original_size=\"\"):\n","  # Get width,height dimensions\n","  if original_size :\n","    width = math.floor(dimensions[0] * image.size[0] / original_size[0])\n","    height = math.floor(dimensions[1] * image.size[1] / original_size[1])\n","  else :\n","    width = dimensions[0]\n","    height = dimensions[1]\n","  # Get starting point (relative must be from 0 to 1)\n","  start_x = math.floor(image.size[0] * start_relative[0])\n","  start_y = math.floor(image.size[1] * start_relative[1])\n","\n","  # Create a frame inside the image\n","  draw = ImageDraw.Draw(image)\n","  draw.rectangle([(start_x,start_y), (start_x + width, start_y + height)],\n","                  fill=None, outline=frame_color, width=frame_width)\n","  return"],"metadata":{"id":"1meTsaETAnAN","executionInfo":{"status":"ok","timestamp":1716139137841,"user_tz":-120,"elapsed":1610,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import os\n","from PIL import Image\n","import shutil\n","\n","## Apply EDSR model to all JPG/PNG images inside folder\n","#NOTE: Make sure images are RGB and not RGBA\n","def apply_EDSR_to_folder(folder=\"./EDSR-PyTorch/test\",\n","                         data_test=\"Demo\", scale=4, pretrain_path=\"\",\n","                         dir_src=\"./EDSR-PyTorch/src\", verbose=True):\n","  ## Change the current working directory to EDSR-PyTorch/src, to run the model\n","  starting_dir = os.getcwd()\n","  current_dir = starting_dir\n","  # Check if our directory is ./EDSR-PyTorch/src\n","  if current_dir.endswith(\"EDSR-PyTorch/src\"):\n","    if verbose :\n","      print(f\"[INFO] The Current working directory is: {current_dir}\\n\")\n","  else:\n","    # Changing the current working directory\n","    os.chdir(dir_src)\n","    if verbose:\n","      print(f\"[INFO] The Current working directory is: {os.getcwd()}\\n\")\n","\n","  ## Use the model\n","  if verbose :\n","    print(f\"[INFO] Using EDSR_x{scale} model as {data_test} with weights from {pretrain_path} on images inside {folder}.\\n\")\n","  !python main_use.py --data_test {data_test} --dir_demo {folder} --scale {scale} --save test --n_resblocks 32 --n_feats 256 --res_scale 0.1 --pre_train {pretrain_path} --test_only --save_results\n","\n","  # Change the current working directory back to the previous one\n","  os.chdir(starting_dir)\n","  if verbose :\n","    print(f\"[INFO] The Current working directory is: {starting_dir}\\n\")\n","\n","  return\n","\n","\n","## Apply EDSR to a single image (returned image is an array)\n","def apply_EDSR_to_image(image, folder=\"./EDSR-PyTorch/test\",\n","                        data_test=\"Demo\", scale=4, pretrain_path=\"\",\n","                        dir_src=\"./EDSR-PyTorch/src\", verbose=True,\n","                        keep_on_disk=False):\n","  # Make copy of image for manipulation (without modifying the original one)\n","  input_image = image.copy()\n","\n","  # If image not RGB, make it RGB\n","  if input_image.mode != \"RGB\":\n","    input_image = input_image.convert(\"RGB\")\n","\n","  # Save image on disk\n","  if not os.path.exists(folder):\n","    os.makedirs(folder, exist_ok=True)\n","  image_path = os.path.join(folder,\"current_image.png\")\n","  input_image.save(image_path)\n","\n","  # Use EDSR model\n","  apply_EDSR_to_folder(folder=folder, data_test=data_test, scale=scale,\n","                       pretrain_path=pretrain_path, dir_src=dir_src, verbose=verbose)\n","\n","  # Read upscaled image\n","  upscaled_image_filename = f\"current_image_x{scale}.png\"\n","  upscaled_image_path = os.path.join(folder,\"results\",upscaled_image_filename)\n","  upscaled_image = cv2.imread(upscaled_image_path)\n","\n","  if not keep_on_disk :\n","    # Delete created directories and files\n","    try:\n","      # Attempt to remove the directory and its contents\n","      shutil.rmtree(folder)\n","    except OSError as e:\n","      # Handle errors, if any\n","      print(f\"Error: {e}\")\n","\n","  # Return upscaled image\n","  return upscaled_image"],"metadata":{"id":"K5MoxKoEwZ9r","executionInfo":{"status":"ok","timestamp":1716139137841,"user_tz":-120,"elapsed":4,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## 5.2 Variables"],"metadata":{"id":"sxqNzwtKt4M2"}},{"cell_type":"code","source":["import os\n","\n","# Required directories\n","current_image_folder = os.path.join(dir_images, \"current_image\")            # ./images/current_image\n","temp_image_folder = os.path.join(dir_images, \"temp_image\")                  # ./images/temp_image\n","\n","for folder_path in [current_image_folder, temp_image_folder] :\n","  if not os.path.exists(folder_path):\n","      os.makedirs(folder_path, exist_ok=True)\n","\n","\n","# SVS image\n","svs_image_names = [\"C3N-00167-21.svs\"]                # Could be a single name or a list of names\n","svs_image_list = [os.path.join(dir_images, image_name) for image_name in svs_image_names]\n","#svs_image_list = get_filepaths(dir_images, file_extension=\".svs\")      # This will retrieve the path to all .svs files in dir_images\n","\n","\n","# Model variables\n","DesiredMagnification = 20.0\n","scale = 4\n","# EDSR 1\n","model1_name = \"EDSR pretrained\"\n","model1_filename = \"edsr_x4-4f62e9ef.pt\"\n","pretrain_path1 = os.path.join(dir_pretrain, model1_filename)\n","# EDSR 2\n","model2_name = \"EDSR trained\"\n","model2_filename = \"edsr_x4-best_2024-03-19.pt\"\n","pretrain_path2 = os.path.join(dir_pretrain, model2_filename)\n","\n","\n","# Measures\n","measures = [\"MSE\", \"PSNR\", \"SSIM\"]\n","\n","\n","# Image composition variables\n","comp_name = \"pretrained_vs_trained\"\n","path_to_save = dir_images\n","\n","base_image_width = 1000\n","start_relative = (0.588,0.267)          # Pixels (34000, 12000) respects image dimension (57767, 44968)\n","crop_size = (500,500)\n","\n","\n","# Aesthetic variables\n","frame_color = \"red\"\n","frame_width = 10\n","font=ImageFont.truetype(font=\"/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf\",size=15)\n","font_color=\"black\"\n"],"metadata":{"id":"Y19os_UCt6s-","executionInfo":{"status":"ok","timestamp":1716139885984,"user_tz":-120,"elapsed":715,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["## 5.3 Displaying image"],"metadata":{"id":"GW_V-_o00Wum"}},{"cell_type":"code","source":["import openslide\n","\n","current_iteration = 1\n","\n","# Go over each SVS image\n","for svs_image_path in svs_image_list :\n","  # Image name\n","  image_name, _ = os.path.splitext(os.path.basename(svs_image_path))\n","\n","  number_of_iterations = len(svs_image_list)\n","  print(f\"Processing image {image_name}: {current_iteration}/{number_of_iterations}\")\n","\n","  # Load SVS image as slide\n","  slide = openslide.OpenSlide(svs_image_path)\n","\n","  # Get base image\n","  base_image = get_base_image(slide, width=base_image_width)\n","\n","  # Get 4 inner images\n","    #Original\n","  image_original, full_image_size = get_original_crop(slide, start_relative=start_relative,\n","                                                      crop_size=crop_size, level=0,\n","                                                      DesiredMagnification=DesiredMagnification)\n","    # Make sure the original one is RGB\n","  if image_original.mode != \"RGB\":\n","    image_original = image_original.convert(\"RGB\")\n","\n","    #Downscale it\n","  image_original_array = image_to_array(image_original, temp_folder=temp_image_folder, keep_on_disk=False)\n","  image_downscaled_array = cv2.resize(image_original_array, None, fx=1/scale, fy=1/scale, interpolation= cv2.INTER_AREA)\n","  image_downscaled = array_to_image(image_downscaled_array, temp_folder=temp_image_folder, keep_on_disk=False)\n","\n","    #Bicubic\n","  image_bicubic = get_bicubic_image(image_downscaled, scale=scale)\n","    #EDSR 1\n","  image_edsr1_array = apply_EDSR_to_image(image_downscaled, folder=current_image_folder,\n","                                          data_test=\"Demo\", scale=scale, pretrain_path=pretrain_path1,\n","                                          dir_src=dir_src, verbose=False)\n","  image_edsr1 = array_to_image(image_edsr1_array, temp_folder=temp_image_folder, keep_on_disk=False)\n","    #EDSR 2\n","  image_edsr2_array = apply_EDSR_to_image(image_downscaled, folder=current_image_folder,\n","                                          data_test=\"Demo\", scale=scale, pretrain_path=pretrain_path2,\n","                                          dir_src=dir_src, verbose=False)\n","  image_edsr2 = array_to_image(image_edsr2_array, temp_folder=temp_image_folder, keep_on_disk=False)\n","\n","  inner_images = [image_original, image_bicubic, image_edsr1, image_edsr2]\n","  # Get measurements for 4 inner images\n","  if len(measures) == 1:\n","    measure=measures[0]\n","    measurements = make_measurements(image_original=image_original, images=inner_images,\n","                                     measure=measure, temp_folder=temp_image_folder)\n","    measurements = round_values_in_list(measurements,decimals=2, na_value=\"\")\n","\n","    inner_images_text = [f\"Original\",\n","                        f\"Bicubic\\n{measure}: {measurements[1]}\",\n","                        f\"{model1_name}\\n{measure}: {measurements[2]}\",\n","                        f\"{model2_name}\\n{measure}: {measurements[3]}\"]\n","  else :\n","    inner_images_text = [f\"Original\\n | \",\n","                        f\"Bicubic\\n\",\n","                        f\"{model1_name}\\n\",\n","                        f\"{model2_name}\\n\"]\n","\n","    for measure_idx, measure in enumerate(measures):\n","      measurements = make_measurements(image_original=image_original, images=inner_images,\n","                                       measure=measure, temp_folder=temp_image_folder)\n","      measurements = round_values_in_list(measurements,decimals=2, na_value=\"\")\n","\n","      # Add measurements\n","      for text_idx in range(1,4):\n","        if measure_idx > 0:\n","          inner_images_text[text_idx] = f\"{inner_images_text[text_idx]} | \"\n","        inner_images_text[text_idx] = f\"{inner_images_text[text_idx]}{measure}: {measurements[text_idx]}\"\n","\n","  # Draw square on base image\n","  draw_rectangle(base_image, start_relative=start_relative, dimensions=crop_size,\n","                 frame_color=frame_color, frame_width=frame_width,\n","                 original_size=full_image_size)\n","\n","  # Make composition and save\n","  export_folder = path_to_save\n","  if not os.path.exists(export_folder):\n","    os.makedirs(export_folder, exist_ok=True)\n","\n","  composition_name = f\"{comp_name}.png\"\n","\n","  export_path = os.path.join(export_folder,composition_name)\n","\n","  create_composition(base_image=base_image, export_path=export_path,\n","                     images=inner_images, images_text=inner_images_text,\n","                     font=font, font_color=font_color)\n","\n","  print(f\"Composition {composition_name} was successfully saved in {export_folder}.\\n\")\n","\n","  # End\n","  current_iteration += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xcL8eMgb1Taa","executionInfo":{"status":"ok","timestamp":1716139918286,"user_tz":-120,"elapsed":30210,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}},"outputId":"585bd451-bfc0-4886-be52-6d4e9abf6efe"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing image C3N-00167-21: 1/1\n","Placing images inside /content/images/current_image into dataloader...\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Loading model...\n","Making model...\n","Load the model from /content/EDSR-PyTorch/pre-train/edsr_x4-4f62e9ef.pt\n","Processing images...\n","100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.38s/it]\n","All images were successfully processed.\n","Placing images inside /content/images/current_image into dataloader...\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Loading model...\n","Making model...\n","Load the model from /content/EDSR-PyTorch/pre-train/edsr_x4-best_2024-03-19.pt\n","Processing images...\n","100%|█████████████████████████████████████████████| 1/1 [00:05<00:00,  5.82s/it]\n","All images were successfully processed.\n","Composition pretrained_vs_trained.png was successfully saved in /content/images.\n","\n"]}]}]}