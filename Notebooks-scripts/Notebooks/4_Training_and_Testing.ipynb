{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyN4vmuiCnSKphXK8G9XVCba"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["In order to perform training on the EDSR x4 model, we need to:\n","\n","1. Get the repository of the model, with all the files and modifications of our interest.\n","2. Have properly located in disk the dataset (or datasets) we are going to use.\n","3. Have properly located in disk the trained model we want to use, if any.\n","4. Either set-up a template with arguments for the model script, or provide such arguments in the command line while running the training.\n","5. Run the training command on a terminal.\n","\n","We have condensed the configurations from our previous notebooks in this single notebook for a simpler use. We can check each corresponding notebook for more information."],"metadata":{"id":"f20o5um2NKMX"}},{"cell_type":"markdown","source":["We will use the directories:"],"metadata":{"id":"abgUF3Wmbgf8"}},{"cell_type":"code","source":["import os\n","\n","dir_base = os.getcwd()\n","dir_edsrpytorch = os.path.join(dir_base,\"EDSR-PyTorch\")     # ./EDSR-PyTorch\n","dir_src = os.path.join(dir_edsrpytorch,\"src\")               # ./EDSR-PyTorch/src\n","dir_pretrain = os.path.join(dir_edsrpytorch, \"pre-train\")   # ./EDSR-PyTorch/pre-train"],"metadata":{"id":"b5t4LlAlbd91"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. Setting up the repository with the model"],"metadata":{"id":"F3IzLXrHhdJE"}},{"cell_type":"markdown","source":["We can additionally place the following files inside the src folder of the repository:\n","* main_use.py: For a simpler application of the main.py script to test a trained model.\n","* freeze.py: To be able to freeze layers of the model during training.\n","\n","For more information about the following cells, we can check our previous notebooks."],"metadata":{"id":"LZpgFMnv0K7V"}},{"cell_type":"markdown","source":["## 1.1 Getting the repository"],"metadata":{"id":"L-G8LbpGhsf2"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kKV_ouE-gqtY","executionInfo":{"status":"ok","timestamp":1716054477460,"user_tz":-120,"elapsed":3627,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}},"outputId":"4e812535-fdbf-4e01-9d75-e39d8c3e1535"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into '/content/EDSR-PyTorch'...\n","remote: Enumerating objects: 806, done.\u001b[K\n","remote: Total 806 (delta 0), reused 0 (delta 0), pack-reused 806\u001b[K\n","Receiving objects: 100% (806/806), 63.09 MiB | 22.36 MiB/s, done.\n","Resolving deltas: 100% (516/516), done.\n"]}],"source":["# Cloning the repository as instructed in https://github.com/sanghyun-son/EDSR-PyTorch\n","!git clone https://github.com/thstkdgus35/EDSR-PyTorch {dir_edsrpytorch}"]},{"cell_type":"markdown","source":["## 1.2 Changes to the option.py file"],"metadata":{"id":"R2qYTyTUZFoz"}},{"cell_type":"markdown","source":["Here we are adding pertinent lines of code to the option.py file in the src folder, to add arguments required for the freeze.py module, the argument save_models_each and an additional line to avoid errors from the argument parser if we want to load the model externally of the script."],"metadata":{"id":"0GHuvNCDZRn-"}},{"cell_type":"code","source":["\"\"\"\n","NOTE: This will always try to read the option.py file from a file\n","named as option-backup.py, which corresponds to the original\n","option.py from the EDSR-PyTorch repository.\n","\n","If such file is not found, the code below will assume it's a fresh\n","clone of the repository, and it will make it.\n","\"\"\"\n","\n","import os\n","\n","# 1. Add this line because the argument parser was giving errors on Google Colab\n","new_line = 'parser.add_argument(\"-f\", \"--file\", required=False)\\n\\n'\n","\n","# 2. Add to the arg parser the arguments for freezing the model before training\n","freezing_arguments = [\n","    \"# Transfer Learning specifications\\n\",\n","    \"parser.add_argument('--param_to_freeze', type=str, default='',\\n\",\n","    \"                    help='named parameters in the model to freeze during training')\\n\",\n","    \"parser.add_argument('--body_to_freeze', type=str, default='',\\n\",\n","    \"                    help='range of layers to freeze in the body of the model during training')\\n\",\n","    \"parser.add_argument('--tail_to_freeze', type=str, default='',\\n\",\n","    \"                    help='range of layers to freeze in the tail of the model during training')\\n\",\n","    \"parser.add_argument('--print_frozen_param', action='store_true',\\n\",\n","    \"                    help='print the number of parameters from the model frozen during training')\\n\",\n","    \"parser.add_argument('--torchinfo_summary', action='store_true',\\n\",\n","    \"                    help='print the model summary using torchinfo')\\n\",\n","    \"parser.add_argument('--torchinfo_inputsize', type=str, default='510,339',\\n\",\n","    \"                    help='input size of a test image to use for printing torchinfo summary')\\n\\n\"\n","]\n","#Note: spaces/tabulations are important.\n","\n","# 3. Add line to save models each number of epochs instead of every epoch\n","savemodels_lines = [\n","    \"parser.add_argument('--save_models_each', type=str, default='1',\\n\",\n","    \"                    help='save models each this number of epochs')\\n\\n\"\n","]\n","\n","# File paths\n","option_file_path = os.path.join(dir_src,'option.py')                 # Original\n","option_file_path_backup = os.path.join(dir_src,'option-backup.py')   # Back-up\n","\n","# If the back-up file is there, read it, or make it if not\n","if os.path.isfile(option_file_path_backup):\n","  # Read the content of the back-up file\n","  with open(option_file_path_backup, 'r') as file:\n","      lines = file.readlines()\n","else:\n","  # Read the content of the original file\n","  with open(option_file_path, 'r') as file:\n","      lines = file.readlines()\n","  # Write the content to the back-up file\n","  with open(option_file_path_backup, 'w') as file:\n","      file.writelines(lines)\n","\n","# 1. Insert new_line at the desired location (between lines 145 and 146)\n","lines.insert(145, new_line)\n","\n","# 2. Insert the freezing arguments lines at the desired location (line 145)\n","for idx,line in enumerate(freezing_arguments):\n","  lines.insert(145+idx, line)\n","\n","# 3. Insert the save models lines at the desired location (line 144)\n","for idx,line in enumerate(savemodels_lines):\n","  lines.insert(144+idx, line)\n","\n","# Write the modified content back to the file\n","with open(option_file_path, 'w') as file:\n","    file.writelines(lines)\n","\n","print(f\"Option file successfully updated in {option_file_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_RLVFV8Er248","executionInfo":{"status":"ok","timestamp":1716052609903,"user_tz":-120,"elapsed":214,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}},"outputId":"01c1e307-c1e7-43de-ff02-2b23c11ea44f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Option file successfully updated in /content/EDSR-PyTorch/src/option.py\n"]}]},{"cell_type":"markdown","source":["## 1.3 Changes to the main.py file"],"metadata":{"id":"wbI8cWUitU9o"}},{"cell_type":"markdown","source":["We need to modify the main.py file to include the import of the freeze module and to apply the freeze_model() function to the model before passing it to the Trainer:"],"metadata":{"id":"F7O7sN0hter8"}},{"cell_type":"code","source":["\"\"\"\n","NOTE: This will always try to read the main.py file from a file\n","named as main-backup.py, which corresponds to the original\n","main.py from the EDSR-PyTorch repository.\n","\n","If such file is not found, the code below will assume it's a fresh\n","clone of the repository, and it will make it.\n","\"\"\"\n","\n","import os\n","\n","# Lines to add\n","new_line1 = \"import freeze\\n\"\n","new_line2 = \"            _model = freeze.freeze_model(_model, args)\\n\"\n","#Note: spaces/tabulations are important.\n","\n","\n","# File paths\n","main_file_path = os.path.join(dir_src,'main.py')                 # Original\n","main_file_path_backup = os.path.join(dir_src,'main-backup.py')   # Back-up\n","\n","# If the back-up file is there, read it, or make it if not\n","if os.path.isfile(main_file_path_backup):\n","  # Read the content of the back-up file\n","  with open(main_file_path_backup, 'r') as file:\n","      lines = file.readlines()\n","else:\n","  # Read the content of the original file\n","  with open(main_file_path, 'r') as file:\n","      lines = file.readlines()\n","  # Write the content to the back-up file\n","  with open(main_file_path_backup, 'w') as file:\n","      file.writelines(lines)\n","\n","# Insert the new lines at the desired location (from bottom to top)\n","lines.insert(23, new_line2)\n","lines.insert(8, new_line1)\n","\n","# Write the modified content back to the file\n","with open(main_file_path, 'w') as file:\n","    file.writelines(lines)\n","\n","print(f\"Option file successfully updated in {main_file_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1pbeq-3Jt7Ik","executionInfo":{"status":"ok","timestamp":1716053077604,"user_tz":-120,"elapsed":210,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}},"outputId":"d3789c92-81af-4593-e09d-7da76806a842"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Option file successfully updated in /content/EDSR-PyTorch/src/main.py\n"]}]},{"cell_type":"markdown","source":["## 1.4 Changes to the _ _ init _ _ file in the \"model\" folder"],"metadata":{"id":"XG_mKpIk1GVg"}},{"cell_type":"markdown","source":["To be able to use the argument save_models_each, we need to modify the _ _ init _ _ file inside the \"model\" folder which is in the src folder of the repository:"],"metadata":{"id":"3G7n7L4D1MDC"}},{"cell_type":"code","source":["\"\"\"\n","NOTE: This will always try to read the __init__.py file from a file\n","named as init-backup.py, which corresponds to the original\n","__init__.py from the EDSR-PyTorch repository.\n","\n","If such file is not found, the code below will assume it's a fresh\n","clone of the repository, and it will make it.\n","\"\"\"\n","\n","# Add these lines\n","new_line1 = '        self.save_models_each = args.save_models_each\\n'\n","new_line2 = '            if (int(epoch) % int(self.save_models_each) == 0):\\n'\n","\n","# Modify these lines (add tab to the original ones)\n","lines_to_modify = [\n","    '                save_dirs.append(\\n',\n","    '                    os.path.join(apath, \\\"model_{}.pt\\\".format(epoch))\\n',\n","    '                )\\n'\n","]\n","#Note: spaces/tabulations are important.\n","\n","# Specify the file path\n","init_file_path = os.path.join(dir_src,'model', '__init__.py')             # Original\n","init_file_path_backup = os.path.join(dir_src,'model', 'init-backup.py')   # Back-up\n","\n","# If the back-up file is there, read it, or make it if not\n","if os.path.isfile(init_file_path_backup):\n","  # Read the content of the back-up file\n","  with open(init_file_path_backup, 'r') as file:\n","      lines = file.readlines()\n","else:\n","  # Read the content of the original file\n","  with open(init_file_path, 'r') as file:\n","      lines = file.readlines()\n","  # Write the content to the back-up file\n","  with open(init_file_path_backup, 'w') as file:\n","      file.writelines(lines)\n","\n","\n","# Modify the lines\n","for idx,line in enumerate(lines_to_modify):\n","  lines[73+idx] = line\n","\n","# Insert lines at the desired locations\n","lines.insert(73, new_line2)\n","lines.insert(32, new_line1)\n","\n","# Write the modified content back to the file\n","with open(init_file_path, 'w') as file:\n","    file.writelines(lines)"],"metadata":{"id":"jhdRBokn0CdD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Place the datasets"],"metadata":{"id":"9EuqejT6byD8"}},{"cell_type":"markdown","source":["We used two different datasets:\n","\n","* General dataset (TCIA): The \"Custom\" folder inside of \"image-data-general\".\n","* Dedicated dataset (Humanitas): The \"Custom\" folder inside of \"image-data-dedicated\".\n","\n","We placed both \"image-data\" folders inside of the \"EDSR-PyTorch\" repository.\n","\n","We need to properly provide the path to our dataset in the arguments we will pass to the main.py script. (Argument dir_data)."],"metadata":{"id":"ZiDIDDTtb6wI"}},{"cell_type":"markdown","source":["# 3. Get a pretrained model"],"metadata":{"id":"_kal_6sfiId_"}},{"cell_type":"markdown","source":["We placed our trained models in a \"pre-train\" folder inside of the \"EDSR-PyTorch\" repository.\n","\n","We need to properly provide the path to our pretrained model (state dictionary file in .pt format) in the arguments we will pass to the main.py script. (Argument pre_train).\n","\n","We can get the pretrained EDSR x4 by the authors with:"],"metadata":{"id":"UkpwKyutcZY9"}},{"cell_type":"code","source":["import os\n","import urllib.request\n","\n","# Pre-train folder\n","if not os.path.exists(dir_pretrain):\n","    os.makedirs(dir_pretrain, exist_ok=True)\n","\n","# Pretrained model\n","pretrain_model = \"edsr_x4-4f62e9ef.pt\"\n","pretrain_model_path = os.path.join(dir_pretrain, pretrain_model)\n","\n","# Download it if not present\n","if not os.path.isfile(pretrain_model_path):\n","  url = \"https://cv.snu.ac.kr/research/EDSR/models/edsr_x4-4f62e9ef.pt\"\n","  with urllib.request.urlopen(url) as response, open(pretrain_model_path, 'wb') as out_file:\n","    data = response.read()\n","    out_file.write(data)\n","  print(f\"Pretrained model {pretrain_model} has been downloaded inside {dir_pretrain}\")\n","else :\n","  print(f\"Using pretrained model {pretrain_model_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IM0ns8qmiDoZ","executionInfo":{"status":"ok","timestamp":1716054499758,"user_tz":-120,"elapsed":19107,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}},"outputId":"6d33e150-1d53-46d5-93f3-074bb30de5e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Pretrained model edsr_x4-4f62e9ef.pt has been downloaded inside /content/EDSR-PyTorch/pre-train\n"]}]},{"cell_type":"markdown","source":["# 4. Setting up a template"],"metadata":{"id":"6_mmxIWTc4w-"}},{"cell_type":"markdown","source":["We can set a template EDSR_custom to use to pass arguments to the main.script by adding it to the template.py file of the EDSR-PyTorch repository:"],"metadata":{"id":"BDa4oGfvc9qm"}},{"cell_type":"code","source":["\"\"\"\n","NOTE: This will always try to read the template.py file from a file\n","named as template-backup.py, which corresponds to the original\n","template.py from the EDSR-PyTorch repository.\n","\n","If such file is not found, the code below will assume it's a fresh\n","clone of the repository, and it will make it.\n","\"\"\"\n","\n","# Lines to add to the file\n","template = [\n","    '    if args.template.find(\\'EDSR_custom\\') >= 0:\\n',\n","    '        args.dir_data =  \\\"../image-data\\\"\\n',\n","    '        args.data_train = \\\"Custom\\\"\\n',\n","    '        args.data_test = \\\"Custom\\\"\\n',\n","    '        args.data_range = \\\"1-2400/2401-2500\\\"\\n',\n","    '        args.ext = \\\"sep\\\"\\n',\n","    '        args.scale = \\\"4\\\"\\n',\n","    '        args.model = \\\"EDSR\\\"\\n',\n","    '        args.pre_train = \\\"../pre-train/edsr_x4-4f62e9ef.pt\\\"\\n',\n","    '        args.n_resblocks = 32\\n',\n","    '        args.n_feats = 256\\n',\n","    '        args.res_scale = 0.1\\n',\n","    '        args.test_every = 100\\n',\n","    '        args.epochs = 11\\n',\n","    '        args.batch_size = 16\\n',\n","    '        args.save = \\\"edsr_x4-train\\\"\\n'\n","]\n","#Note: spaces/tabulations are important.\n","\n","# Specify the file path\n","template_file_path = os.path.join(dir_src,'template.py')\n","\n","# Have a back-up of the original template.py\n","template_file_path_backup = os.path.join(dir_src,'template-backup.py')\n","\n","# If the back-up file is there, read it, or make it if not\n","if os.path.isfile(template_file_path_backup):\n","  # Read the content of the back-up file\n","  with open(template_file_path_backup, 'r') as file:\n","      lines = file.readlines()\n","else:\n","  # Read the content of the original file\n","  with open(template_file_path, 'r') as file:\n","      lines = file.readlines()\n","  # Write the content to the back-up file\n","  with open(template_file_path_backup, 'w') as file:\n","      file.writelines(lines)\n","\n","# Insert the new lines at the desired location (on line 54)\n","for idx,line in enumerate(template):\n","  lines.insert(54+idx, line)\n","\n","# Write the modified content back to the file\n","with open(template_file_path, 'w') as file:\n","    file.writelines(lines)\n","\n","print(f\"Template successfully added to {template_file_path}\")"],"metadata":{"id":"rtH-Ide2dJtX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For different trainings, we should remember to properly indicate the arguments dir_data, data_range, pre_train, epochs and save."],"metadata":{"id":"Ca7Gjs6DdS0_"}},{"cell_type":"markdown","source":["# 5. Running main.py on a terminal"],"metadata":{"id":"XiawAPvkdgab"}},{"cell_type":"markdown","source":["## 5.1 For training"],"metadata":{"id":"5yWYtXLpe53S"}},{"cell_type":"markdown","source":["With all set, we just need to run main.py on a terminal, by providing our arguments of interest (if not already on the template). Arguments we didn't include on the template are:\n","\n","* param_to_freeze: List of the layers names we would want to freeze during training, if any.\n","* body_to_freeze: Range of sub-layers of the \"body\" layer of the model we would want to freeze, if any.\n","* tail_to_freeze: Range of sub-layers of the \"tail\" layer of the model we would want to freeze, if any.\n","* print_frozen_param = True (if we want to print the number of frozen parameters)\n","* save_models = True (to save models beside \"best\" and \"latest\")\n","* save_models_each: The number of how many epochs must pass to save a model during training.\n","* chop = True (memory efficient forward of the model, to avoid getting errors due to insufficient memory)\n","\n","And we can finally perform a training session by running the command on a terminal:"],"metadata":{"id":"zz1b9K-edjjl"}},{"cell_type":"code","source":["# Command to train the model (from the src folder)\n","!python main.py --template EDSR_custom --save_models --save_models_each 5 --chop"],"metadata":{"id":"H8tAbfbme0GW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5.2 For a quick testing"],"metadata":{"id":"7cJziQj-e8fT"}},{"cell_type":"markdown","source":["We prepared a main_use.py script as a simpler alternative of the main.py script. This file must be placed in the src folder of the repository.\n","\n","We can perform a quick application of a trained model by providing the following arguments:\n","\n","* dir_demo: Path to the folder containing the images we want to upscale (in either PNG or JPG format).\n","* pretrain_path: Path to the state dictionary file of the EDSR x4 model we want to use to upscale the images.\n","\n","And we can run the following command on a terminal:"],"metadata":{"id":"0n-4hFvS24GZ"}},{"cell_type":"code","source":["# Command to train the model (from the src folder)\n","!python main_use.py --data_test Demo --dir_demo {dir_demo} --scale 4 --n_resblocks 32 --n_feats 256 --res_scale 0.1 --pre_train {pretrain_path} --test_only --save_results"],"metadata":{"id":"FbFrfH5Gvcqt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We then can expect a folder named \"experiment\" inside the folder dir_demo, containing the Super-Resolution upscalings of the images inside of dir_demo."],"metadata":{"id":"bqVvwGNR3mZL"}}]}