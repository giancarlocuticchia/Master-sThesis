{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPo+cVg4+/kjOHJoBytoH1b"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["In order to understand how the freeze.py module we made works and how to freeze layers during training, we can follow the notebook below:\n","\n","1. First we need to get the model, a pretrained model (if we want), and set up the appropiate arguments, like in our notebook 0_The_EDSRx4_model.ipynb. (Note: we could ignore this part if we did it already).\n","2. Then we can see the parameters that can be trainable in the model, and how to prevent them to update during the training (freezing).\n","3. Set up the repository in order to use the freeze.py module."],"metadata":{"id":"_3hPBiSOg40X"}},{"cell_type":"markdown","source":["We will use the directories:"],"metadata":{"id":"qPDMaSwyhkjr"}},{"cell_type":"code","source":["import os\n","\n","dir_base = os.getcwd()\n","dir_edsrpytorch = os.path.join(dir_base,\"EDSR-PyTorch\")     # ./EDSR-PyTorch\n","dir_src = os.path.join(dir_edsrpytorch,\"src\")               # ./EDSR-PyTorch/src\n","dir_pretrain = os.path.join(dir_edsrpytorch, \"pre-train\")   # ./EDSR-PyTorch/pre-train"],"metadata":{"id":"na0u_tM_hoH1","executionInfo":{"status":"ok","timestamp":1716050134690,"user_tz":-120,"elapsed":236,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# 1. Getting the model ready"],"metadata":{"id":"F3IzLXrHhdJE"}},{"cell_type":"markdown","source":["## 1.1 Getting the repository"],"metadata":{"id":"L-G8LbpGhsf2"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kKV_ouE-gqtY","executionInfo":{"status":"ok","timestamp":1716050140799,"user_tz":-120,"elapsed":3466,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}},"outputId":"8ec3b8cb-888b-4e92-bc8f-c5e682fd136a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into '/content/EDSR-PyTorch'...\n","remote: Enumerating objects: 806, done.\u001b[K\n","remote: Total 806 (delta 0), reused 0 (delta 0), pack-reused 806\u001b[K\n","Receiving objects: 100% (806/806), 63.09 MiB | 30.40 MiB/s, done.\n","Resolving deltas: 100% (516/516), done.\n"]}],"source":["# Cloning the repository as instructed in https://github.com/sanghyun-son/EDSR-PyTorch\n","!git clone https://github.com/thstkdgus35/EDSR-PyTorch {dir_edsrpytorch}"]},{"cell_type":"markdown","source":["## 1.2 Get a pretrained model"],"metadata":{"id":"_kal_6sfiId_"}},{"cell_type":"code","source":["import os\n","import urllib.request\n","\n","# Pre-train folder\n","if not os.path.exists(dir_pretrain):\n","    os.makedirs(dir_pretrain, exist_ok=True)\n","\n","# Pretrained model\n","pretrain_model = \"edsr_x4-4f62e9ef.pt\"\n","pretrain_model_path = os.path.join(dir_pretrain, pretrain_model)\n","\n","# Download it if not present\n","if not os.path.isfile(pretrain_model_path):\n","  url = \"https://cv.snu.ac.kr/research/EDSR/models/edsr_x4-4f62e9ef.pt\"\n","  with urllib.request.urlopen(url) as response, open(pretrain_model_path, 'wb') as out_file:\n","    data = response.read()\n","    out_file.write(data)\n","  print(f\"Pretrained model {pretrain_model} has been downloaded inside {dir_pretrain}\")\n","else :\n","  print(f\"Using pretrained model {pretrain_model_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IM0ns8qmiDoZ","executionInfo":{"status":"ok","timestamp":1716050198475,"user_tz":-120,"elapsed":50136,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}},"outputId":"0320c4c9-8b8b-422b-b0da-e109b5bb00e2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Pretrained model edsr_x4-4f62e9ef.pt has been downloaded inside /content/EDSR-PyTorch/pre-train\n"]}]},{"cell_type":"markdown","source":["## 1.3 Move current working directory to the src folder"],"metadata":{"id":"_e9dIasAiUUG"}},{"cell_type":"code","source":["## Change the current working directory to EDSR-PyTorch/src, to run the model\n","import os\n","\n","os.chdir(dir_src)\n","print(f\"The Current working directory is: {os.getcwd()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nrKYdEnMibBA","executionInfo":{"status":"ok","timestamp":1716050202093,"user_tz":-120,"elapsed":229,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}},"outputId":"d3b5593d-9cc4-4dec-dc8e-d672d9b685ff"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["The Current working directory is: /content/EDSR-PyTorch/src\n"]}]},{"cell_type":"markdown","source":["We can change the current working directory back to the base directory at any time by uncommenting and running:"],"metadata":{"id":"V2aSDwwkihH_"}},{"cell_type":"code","source":["#os.chdir(dir_base)\n","#print(f\"The Current working directory is: {os.getcwd()}\")"],"metadata":{"id":"1nWGztutigXl","executionInfo":{"status":"ok","timestamp":1716050204280,"user_tz":-120,"elapsed":228,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## 1.4 Setting up the option.py and template.py files"],"metadata":{"id":"2x4goCc7intI"}},{"cell_type":"code","source":["# Setting up the option.py file\n","\"\"\"\n","NOTE: This will always try to read the option.py file from a file\n","named as option-backup.py, which corresponds to the original\n","option.py from the EDSR-PyTorch repository.\n","\n","If such file is not found, the code below will assume it's a fresh\n","clone of the repository, and it will make it.\n","\"\"\"\n","\n","import os\n","\n","# Line we want to add\n","new_line = 'parser.add_argument(\"-f\", \"--file\", required=False)\\n\\n'\n","\n","# File paths\n","option_file_path = os.path.join(dir_src,'option.py')                 # Original\n","option_file_path_backup = os.path.join(dir_src,'option-backup.py')   # Back-up\n","\n","# If the back-up file is there, read it, or make it if not\n","if os.path.isfile(option_file_path_backup):\n","  # Read the content of the back-up file\n","  with open(option_file_path_backup, 'r') as file:\n","      lines = file.readlines()\n","else:\n","  # Read the content of the original file\n","  with open(option_file_path, 'r') as file:\n","      lines = file.readlines()\n","  # Write the content to the back-up file\n","  with open(option_file_path_backup, 'w') as file:\n","      file.writelines(lines)\n","\n","# Insert the new line at the desired location (between lines 145 and 146)\n","lines.insert(145, new_line)\n","\n","# Write the modified content back to the file\n","with open(option_file_path, 'w') as file:\n","    file.writelines(lines)\n","\n","print(f\"Option file successfully updated in {option_file_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tG7L95J3iuRh","executionInfo":{"status":"ok","timestamp":1716050206515,"user_tz":-120,"elapsed":220,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}},"outputId":"785523ce-02bd-48cf-9660-65d0b0c8a1a9"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Option file successfully updated in /content/EDSR-PyTorch/src/option.py\n"]}]},{"cell_type":"code","source":["# Setting up the template.py file\n","\"\"\"\n","NOTE: This will always try to read the template.py file from a file\n","named as template-backup.py, which corresponds to the original\n","template.py from the EDSR-PyTorch repository.\n","\n","If such file is not found, the code below will assume it's a fresh\n","clone of the repository, and it will make it.\n","\"\"\"\n","\n","# Lines to add to the file\n","template = [\n","    '    if args.template.find(\\'EDSR_custom\\') >= 0:\\n',\n","    '        args.dir_data =  \\\"../image-data\\\"\\n',\n","    '        args.data_train = \\\"Custom\\\"\\n',\n","    '        args.data_test = \\\"Custom\\\"\\n',\n","    '        args.data_range = \\\"1-2400/2401-2500\\\"\\n',\n","    '        args.ext = \\\"sep\\\"\\n',\n","    '        args.scale = \\\"4\\\"\\n',\n","    '        args.model = \\\"EDSR\\\"\\n',\n","    '        args.pre_train = \\\"../pre-train/edsr_x4-4f62e9ef.pt\\\"\\n',\n","    '        args.n_resblocks = 32\\n',\n","    '        args.n_feats = 256\\n',\n","    '        args.res_scale = 0.1\\n',\n","    '        args.test_every = 100\\n',\n","    '        args.epochs = 11\\n',\n","    '        args.batch_size = 16\\n',\n","    '        args.save = \\\"edsr_x4-train\\\"\\n'\n","]\n","#Note: spaces/tabulations are important.\n","\n","# Specify the file path\n","template_file_path = os.path.join(dir_src,'template.py')\n","\n","# Have a back-up of the original template.py\n","template_file_path_backup = os.path.join(dir_src,'template-backup.py')\n","\n","# If the back-up file is there, read it, or make it if not\n","if os.path.isfile(template_file_path_backup):\n","  # Read the content of the back-up file\n","  with open(template_file_path_backup, 'r') as file:\n","      lines = file.readlines()\n","else:\n","  # Read the content of the original file\n","  with open(template_file_path, 'r') as file:\n","      lines = file.readlines()\n","  # Write the content to the back-up file\n","  with open(template_file_path_backup, 'w') as file:\n","      file.writelines(lines)\n","\n","# Insert the new lines at the desired location (on line 54)\n","for idx,line in enumerate(template):\n","  lines.insert(54+idx, line)\n","\n","# Write the modified content back to the file\n","with open(template_file_path, 'w') as file:\n","    file.writelines(lines)\n","\n","print(f\"Template successfully added to {template_file_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wowGRgV1iyfk","executionInfo":{"status":"ok","timestamp":1716050208931,"user_tz":-120,"elapsed":212,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}},"outputId":"502044f7-30a3-4c24-c5d2-853baaac2ad0"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Template successfully added to /content/EDSR-PyTorch/src/template.py\n"]}]},{"cell_type":"markdown","source":["## 1.5 Setting up the arguments args"],"metadata":{"id":"WmFQxm6ii6mx"}},{"cell_type":"code","source":["from option import args\n","import template\n","\n","# Use the desired template of args:\n","args.template = \"EDSR_custom\"\n","template.set_template(args)\n","\n","# Set-up args as in the option.py file, after setting the template:\n","args.scale = list(map(lambda x: int(x), args.scale.split('+')))\n","args.data_train = args.data_train.split('+')\n","args.data_test = args.data_test.split('+')\n","\n","if args.epochs == 0:\n","  args.epochs = 1e8\n","\n","for arg in vars(args):\n","  if vars(args)[arg] == 'True':\n","    vars(args)[arg] = True\n","  elif vars(args)[arg] == 'False':\n","    vars(args)[arg] = False\n","\n","# Set-up additional parameters\n","args.chop = True\n","args.save_results = True\n","args.param_to_freeze = \"\"\n","args.body_to_freeze = \"\"\n","args.tail_to_freeze = \"\"\n","args.print_frozen_param = True\n","args.save_models_each = 3"],"metadata":{"id":"-q4JbSiei9p3","executionInfo":{"status":"ok","timestamp":1716050212201,"user_tz":-120,"elapsed":221,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# 2. Looking for the trainable parameters on the model"],"metadata":{"id":"nXSHEGRXjGFJ"}},{"cell_type":"markdown","source":["## 2.1 Loading the model"],"metadata":{"id":"qQ0OGx1pjOo_"}},{"cell_type":"code","source":["import torch\n","\n","import utility\n","import model\n","\n","torch.manual_seed(args.seed)\n","checkpoint = utility.checkpoint(args)\n","\n","# Load the model\n","model = model.Model(args, checkpoint)\n","\n","# Print it (optional)\n","#print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yFDCIPiMjMLX","executionInfo":{"status":"ok","timestamp":1716050220333,"user_tz":-120,"elapsed":5836,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}},"outputId":"f75477f3-bdce-44a5-f40f-4a25fe88fb34"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Making model...\n","Load the model from ../pre-train/edsr_x4-4f62e9ef.pt\n"]}]},{"cell_type":"markdown","source":["## 2.2 Model parameters"],"metadata":{"id":"tF7oVXnajUwt"}},{"cell_type":"markdown","source":["Once the model is loaded, we can see it's \"named parameters\" by using the named_parameters() method, as shown below:"],"metadata":{"id":"lfDL5toijZAK"}},{"cell_type":"code","source":["for name,value in model.named_parameters():\n","  print(name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aHpjrGVTjYLV","executionInfo":{"status":"ok","timestamp":1716050223295,"user_tz":-120,"elapsed":226,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}},"outputId":"7ac5de25-54a4-4a94-af64-bd24cb8bc55a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["model.sub_mean.weight\n","model.sub_mean.bias\n","model.add_mean.weight\n","model.add_mean.bias\n","model.head.0.weight\n","model.head.0.bias\n","model.body.0.body.0.weight\n","model.body.0.body.0.bias\n","model.body.0.body.2.weight\n","model.body.0.body.2.bias\n","model.body.1.body.0.weight\n","model.body.1.body.0.bias\n","model.body.1.body.2.weight\n","model.body.1.body.2.bias\n","model.body.2.body.0.weight\n","model.body.2.body.0.bias\n","model.body.2.body.2.weight\n","model.body.2.body.2.bias\n","model.body.3.body.0.weight\n","model.body.3.body.0.bias\n","model.body.3.body.2.weight\n","model.body.3.body.2.bias\n","model.body.4.body.0.weight\n","model.body.4.body.0.bias\n","model.body.4.body.2.weight\n","model.body.4.body.2.bias\n","model.body.5.body.0.weight\n","model.body.5.body.0.bias\n","model.body.5.body.2.weight\n","model.body.5.body.2.bias\n","model.body.6.body.0.weight\n","model.body.6.body.0.bias\n","model.body.6.body.2.weight\n","model.body.6.body.2.bias\n","model.body.7.body.0.weight\n","model.body.7.body.0.bias\n","model.body.7.body.2.weight\n","model.body.7.body.2.bias\n","model.body.8.body.0.weight\n","model.body.8.body.0.bias\n","model.body.8.body.2.weight\n","model.body.8.body.2.bias\n","model.body.9.body.0.weight\n","model.body.9.body.0.bias\n","model.body.9.body.2.weight\n","model.body.9.body.2.bias\n","model.body.10.body.0.weight\n","model.body.10.body.0.bias\n","model.body.10.body.2.weight\n","model.body.10.body.2.bias\n","model.body.11.body.0.weight\n","model.body.11.body.0.bias\n","model.body.11.body.2.weight\n","model.body.11.body.2.bias\n","model.body.12.body.0.weight\n","model.body.12.body.0.bias\n","model.body.12.body.2.weight\n","model.body.12.body.2.bias\n","model.body.13.body.0.weight\n","model.body.13.body.0.bias\n","model.body.13.body.2.weight\n","model.body.13.body.2.bias\n","model.body.14.body.0.weight\n","model.body.14.body.0.bias\n","model.body.14.body.2.weight\n","model.body.14.body.2.bias\n","model.body.15.body.0.weight\n","model.body.15.body.0.bias\n","model.body.15.body.2.weight\n","model.body.15.body.2.bias\n","model.body.16.body.0.weight\n","model.body.16.body.0.bias\n","model.body.16.body.2.weight\n","model.body.16.body.2.bias\n","model.body.17.body.0.weight\n","model.body.17.body.0.bias\n","model.body.17.body.2.weight\n","model.body.17.body.2.bias\n","model.body.18.body.0.weight\n","model.body.18.body.0.bias\n","model.body.18.body.2.weight\n","model.body.18.body.2.bias\n","model.body.19.body.0.weight\n","model.body.19.body.0.bias\n","model.body.19.body.2.weight\n","model.body.19.body.2.bias\n","model.body.20.body.0.weight\n","model.body.20.body.0.bias\n","model.body.20.body.2.weight\n","model.body.20.body.2.bias\n","model.body.21.body.0.weight\n","model.body.21.body.0.bias\n","model.body.21.body.2.weight\n","model.body.21.body.2.bias\n","model.body.22.body.0.weight\n","model.body.22.body.0.bias\n","model.body.22.body.2.weight\n","model.body.22.body.2.bias\n","model.body.23.body.0.weight\n","model.body.23.body.0.bias\n","model.body.23.body.2.weight\n","model.body.23.body.2.bias\n","model.body.24.body.0.weight\n","model.body.24.body.0.bias\n","model.body.24.body.2.weight\n","model.body.24.body.2.bias\n","model.body.25.body.0.weight\n","model.body.25.body.0.bias\n","model.body.25.body.2.weight\n","model.body.25.body.2.bias\n","model.body.26.body.0.weight\n","model.body.26.body.0.bias\n","model.body.26.body.2.weight\n","model.body.26.body.2.bias\n","model.body.27.body.0.weight\n","model.body.27.body.0.bias\n","model.body.27.body.2.weight\n","model.body.27.body.2.bias\n","model.body.28.body.0.weight\n","model.body.28.body.0.bias\n","model.body.28.body.2.weight\n","model.body.28.body.2.bias\n","model.body.29.body.0.weight\n","model.body.29.body.0.bias\n","model.body.29.body.2.weight\n","model.body.29.body.2.bias\n","model.body.30.body.0.weight\n","model.body.30.body.0.bias\n","model.body.30.body.2.weight\n","model.body.30.body.2.bias\n","model.body.31.body.0.weight\n","model.body.31.body.0.bias\n","model.body.31.body.2.weight\n","model.body.31.body.2.bias\n","model.body.32.weight\n","model.body.32.bias\n","model.tail.0.0.weight\n","model.tail.0.0.bias\n","model.tail.0.2.weight\n","model.tail.0.2.bias\n","model.tail.1.weight\n","model.tail.1.bias\n"]}]},{"cell_type":"markdown","source":["There we can see the parameters \"weight\" and \"bias\" for each layer of the model. The layers are:\n","\n","* Sub_mean\n","* Add_mean\n","* Head\n","* Body: 32 Resblocks (from 0 to 31) and a last Conv2d layer (32). Each Resblock is also sub-divided into two more sub-layers (0 and 2)\n","* Tail: Upsampler (0) divided in two sub-layers (0 and 2), and a final Conv2d layer (1)."],"metadata":{"id":"lKRr5cmWkXTs"}},{"cell_type":"markdown","source":["## 2.3 Disabling gradients on the parameters"],"metadata":{"id":"OCMROjrFnQhB"}},{"cell_type":"markdown","source":["We can \"freeze\" the corresponding parameter by setting the attribute requires_grad of its value to False. For example, if we would like to disable gradients from the head layers:"],"metadata":{"id":"yLT9ba9jnVKP"}},{"cell_type":"code","source":["parameter_to_freeze = \"head\"\n","\n","# We want:\n","#model.head.0.weight.requires_grad = False\n","#model.head.0.bias.requires_grad = False\n","\n","# We do:\n","for name,value in model.named_parameters():\n","  if name.split(\".\")[1] == parameter_to_freeze :\n","    value.requires_grad = False\n","\n","# We could print them again to see\n","for name,value in model.named_parameters():\n","  print(f\"Is {name} trainable? {value.requires_grad}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i-Xas1FHlmve","executionInfo":{"status":"ok","timestamp":1716051002638,"user_tz":-120,"elapsed":248,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}},"outputId":"ab03dae7-7030-47a9-95b0-9097bdc6d340"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Is model.sub_mean.weight trainable? False\n","Is model.sub_mean.bias trainable? False\n","Is model.add_mean.weight trainable? False\n","Is model.add_mean.bias trainable? False\n","Is model.head.0.weight trainable? False\n","Is model.head.0.bias trainable? False\n","Is model.body.0.body.0.weight trainable? True\n","Is model.body.0.body.0.bias trainable? True\n","Is model.body.0.body.2.weight trainable? True\n","Is model.body.0.body.2.bias trainable? True\n","Is model.body.1.body.0.weight trainable? True\n","Is model.body.1.body.0.bias trainable? True\n","Is model.body.1.body.2.weight trainable? True\n","Is model.body.1.body.2.bias trainable? True\n","Is model.body.2.body.0.weight trainable? True\n","Is model.body.2.body.0.bias trainable? True\n","Is model.body.2.body.2.weight trainable? True\n","Is model.body.2.body.2.bias trainable? True\n","Is model.body.3.body.0.weight trainable? True\n","Is model.body.3.body.0.bias trainable? True\n","Is model.body.3.body.2.weight trainable? True\n","Is model.body.3.body.2.bias trainable? True\n","Is model.body.4.body.0.weight trainable? True\n","Is model.body.4.body.0.bias trainable? True\n","Is model.body.4.body.2.weight trainable? True\n","Is model.body.4.body.2.bias trainable? True\n","Is model.body.5.body.0.weight trainable? True\n","Is model.body.5.body.0.bias trainable? True\n","Is model.body.5.body.2.weight trainable? True\n","Is model.body.5.body.2.bias trainable? True\n","Is model.body.6.body.0.weight trainable? True\n","Is model.body.6.body.0.bias trainable? True\n","Is model.body.6.body.2.weight trainable? True\n","Is model.body.6.body.2.bias trainable? True\n","Is model.body.7.body.0.weight trainable? True\n","Is model.body.7.body.0.bias trainable? True\n","Is model.body.7.body.2.weight trainable? True\n","Is model.body.7.body.2.bias trainable? True\n","Is model.body.8.body.0.weight trainable? True\n","Is model.body.8.body.0.bias trainable? True\n","Is model.body.8.body.2.weight trainable? True\n","Is model.body.8.body.2.bias trainable? True\n","Is model.body.9.body.0.weight trainable? True\n","Is model.body.9.body.0.bias trainable? True\n","Is model.body.9.body.2.weight trainable? True\n","Is model.body.9.body.2.bias trainable? True\n","Is model.body.10.body.0.weight trainable? True\n","Is model.body.10.body.0.bias trainable? True\n","Is model.body.10.body.2.weight trainable? True\n","Is model.body.10.body.2.bias trainable? True\n","Is model.body.11.body.0.weight trainable? True\n","Is model.body.11.body.0.bias trainable? True\n","Is model.body.11.body.2.weight trainable? True\n","Is model.body.11.body.2.bias trainable? True\n","Is model.body.12.body.0.weight trainable? True\n","Is model.body.12.body.0.bias trainable? True\n","Is model.body.12.body.2.weight trainable? True\n","Is model.body.12.body.2.bias trainable? True\n","Is model.body.13.body.0.weight trainable? True\n","Is model.body.13.body.0.bias trainable? True\n","Is model.body.13.body.2.weight trainable? True\n","Is model.body.13.body.2.bias trainable? True\n","Is model.body.14.body.0.weight trainable? True\n","Is model.body.14.body.0.bias trainable? True\n","Is model.body.14.body.2.weight trainable? True\n","Is model.body.14.body.2.bias trainable? True\n","Is model.body.15.body.0.weight trainable? True\n","Is model.body.15.body.0.bias trainable? True\n","Is model.body.15.body.2.weight trainable? True\n","Is model.body.15.body.2.bias trainable? True\n","Is model.body.16.body.0.weight trainable? True\n","Is model.body.16.body.0.bias trainable? True\n","Is model.body.16.body.2.weight trainable? True\n","Is model.body.16.body.2.bias trainable? True\n","Is model.body.17.body.0.weight trainable? True\n","Is model.body.17.body.0.bias trainable? True\n","Is model.body.17.body.2.weight trainable? True\n","Is model.body.17.body.2.bias trainable? True\n","Is model.body.18.body.0.weight trainable? True\n","Is model.body.18.body.0.bias trainable? True\n","Is model.body.18.body.2.weight trainable? True\n","Is model.body.18.body.2.bias trainable? True\n","Is model.body.19.body.0.weight trainable? True\n","Is model.body.19.body.0.bias trainable? True\n","Is model.body.19.body.2.weight trainable? True\n","Is model.body.19.body.2.bias trainable? True\n","Is model.body.20.body.0.weight trainable? True\n","Is model.body.20.body.0.bias trainable? True\n","Is model.body.20.body.2.weight trainable? True\n","Is model.body.20.body.2.bias trainable? True\n","Is model.body.21.body.0.weight trainable? True\n","Is model.body.21.body.0.bias trainable? True\n","Is model.body.21.body.2.weight trainable? True\n","Is model.body.21.body.2.bias trainable? True\n","Is model.body.22.body.0.weight trainable? True\n","Is model.body.22.body.0.bias trainable? True\n","Is model.body.22.body.2.weight trainable? True\n","Is model.body.22.body.2.bias trainable? True\n","Is model.body.23.body.0.weight trainable? True\n","Is model.body.23.body.0.bias trainable? True\n","Is model.body.23.body.2.weight trainable? True\n","Is model.body.23.body.2.bias trainable? True\n","Is model.body.24.body.0.weight trainable? True\n","Is model.body.24.body.0.bias trainable? True\n","Is model.body.24.body.2.weight trainable? True\n","Is model.body.24.body.2.bias trainable? True\n","Is model.body.25.body.0.weight trainable? True\n","Is model.body.25.body.0.bias trainable? True\n","Is model.body.25.body.2.weight trainable? True\n","Is model.body.25.body.2.bias trainable? True\n","Is model.body.26.body.0.weight trainable? True\n","Is model.body.26.body.0.bias trainable? True\n","Is model.body.26.body.2.weight trainable? True\n","Is model.body.26.body.2.bias trainable? True\n","Is model.body.27.body.0.weight trainable? True\n","Is model.body.27.body.0.bias trainable? True\n","Is model.body.27.body.2.weight trainable? True\n","Is model.body.27.body.2.bias trainable? True\n","Is model.body.28.body.0.weight trainable? True\n","Is model.body.28.body.0.bias trainable? True\n","Is model.body.28.body.2.weight trainable? True\n","Is model.body.28.body.2.bias trainable? True\n","Is model.body.29.body.0.weight trainable? True\n","Is model.body.29.body.0.bias trainable? True\n","Is model.body.29.body.2.weight trainable? True\n","Is model.body.29.body.2.bias trainable? True\n","Is model.body.30.body.0.weight trainable? True\n","Is model.body.30.body.0.bias trainable? True\n","Is model.body.30.body.2.weight trainable? True\n","Is model.body.30.body.2.bias trainable? True\n","Is model.body.31.body.0.weight trainable? True\n","Is model.body.31.body.0.bias trainable? True\n","Is model.body.31.body.2.weight trainable? True\n","Is model.body.31.body.2.bias trainable? True\n","Is model.body.32.weight trainable? True\n","Is model.body.32.bias trainable? True\n","Is model.tail.0.0.weight trainable? True\n","Is model.tail.0.0.bias trainable? True\n","Is model.tail.0.2.weight trainable? True\n","Is model.tail.0.2.bias trainable? True\n","Is model.tail.1.weight trainable? True\n","Is model.tail.1.bias trainable? True\n"]}]},{"cell_type":"markdown","source":["## 2.4 Visualizing it with torchinfo"],"metadata":{"id":"WoBDNy4_lmWx"}},{"cell_type":"markdown","source":["NOTE: If torchinfo is not installed, we can install it in Google Colab by doing:"],"metadata":{"id":"ll5oJw7yne0j"}},{"cell_type":"code","source":["# Checking for torchinfo\n","try:\n","  from torchinfo import summary\n","except:\n","  !pip install -q torchinfo\n","  from torchinfo import summary"],"metadata":{"id":"-lo4OqzdngRz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchinfo import summary\n","\n","batch_size = 16\n","image_dim = (3, 64, 64)\n","\n","summary(model=model,\n","        input_size=(batch_size, *image_dim),\n","        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n","        col_width=20,\n","        cache_forward_pass=True,\n","        depth=5,\n","        mode=\"train\",\n","        row_settings=[\"var_names\"],\n","        idx_scale=0\n",")"],"metadata":{"id":"7X4p9ucEnixK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["There we can see in the last column \"Trainable\" if the parameter is trainable or not (frozen)."],"metadata":{"id":"aLyjkhcPnrTR"}},{"cell_type":"markdown","source":["# 3. Setting up the freeze.py module"],"metadata":{"id":"04fZ08yYqZHy"}},{"cell_type":"markdown","source":["We prepared a freeze.py file with a freeze_model() function to be able to select which parameters from to the model to freeze, if any.\n","\n","In order to use it, we need:\n","* Place the freeze.py file inside of the src folder.\n","* Modify the option.py file in order to add the arguments required to use the freeze_model() function.\n","* Modify the main.py file in order to insert the use of the freeze_model() function.\n","* Pass the corresponding parameters to the command to train the model on the terminal."],"metadata":{"id":"0DlcWyVRqcXk"}},{"cell_type":"markdown","source":["## 3.1 Changes to the option.py file"],"metadata":{"id":"HtZWTfbTry1y"}},{"cell_type":"markdown","source":["We need to add the following parameters:\n","* param_to_freeze: names of the parameters to freeze (sub_mean, add_mean, head, body or tail)\n","* body_to_freeze: layers of the body to freeze\n","* tail_to_freeze: layers of the tail to freeze\n","* print_frozen_param: if True, prints the number of parameters which gradients are disable during the training\n","* torchinfo_summary: if True, will print a summary of the model structure using torchinfo\n","* torchinfo_inputsize: input size to use in the summary function from torhinfo\n","\n","We can do it with the following code:"],"metadata":{"id":"-UK_1Xfnr3lv"}},{"cell_type":"code","source":["\"\"\"\n","NOTE: This will always try to read the option.py file from a file\n","named as option-backup.py, which corresponds to the original\n","option.py from the EDSR-PyTorch repository.\n","\n","If such file is not found, the code below will assume it's a fresh\n","clone of the repository, and it will make it.\n","\"\"\"\n","\n","import os\n","\n","# 1. Add this line because the argument parser was giving errors on Google Colab\n","new_line = 'parser.add_argument(\"-f\", \"--file\", required=False)\\n\\n'\n","\n","# 2. Add to the arg parser the arguments for freezing the model before training\n","freezing_arguments = [\n","    \"# Transfer Learning specifications\\n\",\n","    \"parser.add_argument('--param_to_freeze', type=str, default='',\\n\",\n","    \"                    help='named parameters in the model to freeze during training')\\n\",\n","    \"parser.add_argument('--body_to_freeze', type=str, default='',\\n\",\n","    \"                    help='range of layers to freeze in the body of the model during training')\\n\",\n","    \"parser.add_argument('--tail_to_freeze', type=str, default='',\\n\",\n","    \"                    help='range of layers to freeze in the tail of the model during training')\\n\",\n","    \"parser.add_argument('--print_frozen_param', action='store_true',\\n\",\n","    \"                    help='print the number of parameters from the model frozen during training')\\n\",\n","    \"parser.add_argument('--torchinfo_summary', action='store_true',\\n\",\n","    \"                    help='print the model summary using torchinfo')\\n\",\n","    \"parser.add_argument('--torchinfo_inputsize', type=str, default='510,339',\\n\",\n","    \"                    help='input size of a test image to use for printing torchinfo summary')\\n\\n\"\n","]\n","#Note: spaces/tabulations are important.\n","\n","\n","# File paths\n","option_file_path = os.path.join(dir_src,'option.py')                 # Original\n","option_file_path_backup = os.path.join(dir_src,'option-backup.py')   # Back-up\n","\n","# If the back-up file is there, read it, or make it if not\n","if os.path.isfile(option_file_path_backup):\n","  # Read the content of the back-up file\n","  with open(option_file_path_backup, 'r') as file:\n","      lines = file.readlines()\n","else:\n","  # Read the content of the original file\n","  with open(option_file_path, 'r') as file:\n","      lines = file.readlines()\n","  # Write the content to the back-up file\n","  with open(option_file_path_backup, 'w') as file:\n","      file.writelines(lines)\n","\n","# 1. Insert new_line at the desired location (between lines 145 and 146)\n","lines.insert(145, new_line)\n","\n","# 2. Insert the freezing arguments lines at the desired location (line 145)\n","for idx,line in enumerate(freezing_arguments):\n","  lines.insert(145+idx, line)\n","\n","# Write the modified content back to the file\n","with open(option_file_path, 'w') as file:\n","    file.writelines(lines)\n","\n","print(f\"Option file successfully updated in {option_file_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_RLVFV8Er248","executionInfo":{"status":"ok","timestamp":1716052609903,"user_tz":-120,"elapsed":214,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}},"outputId":"01c1e307-c1e7-43de-ff02-2b23c11ea44f"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Option file successfully updated in /content/EDSR-PyTorch/src/option.py\n"]}]},{"cell_type":"markdown","source":["## 3.2 Changes to the main.py file"],"metadata":{"id":"wbI8cWUitU9o"}},{"cell_type":"markdown","source":["We need to import the freeze module and to apply the freeze_model() function to the model before passing it to the Trainer in the main.py script, we can do it with:"],"metadata":{"id":"F7O7sN0hter8"}},{"cell_type":"code","source":["\"\"\"\n","NOTE: This will always try to read the main.py file from a file\n","named as main-backup.py, which corresponds to the original\n","main.py from the EDSR-PyTorch repository.\n","\n","If such file is not found, the code below will assume it's a fresh\n","clone of the repository, and it will make it.\n","\"\"\"\n","\n","import os\n","\n","# Lines to add\n","new_line1 = \"import freeze\\n\"\n","new_line2 = \"            _model = freeze.freeze_model(_model, args)\\n\"\n","#Note: spaces/tabulations are important.\n","\n","\n","# File paths\n","main_file_path = os.path.join(dir_src,'main.py')                 # Original\n","main_file_path_backup = os.path.join(dir_src,'main-backup.py')   # Back-up\n","\n","# If the back-up file is there, read it, or make it if not\n","if os.path.isfile(main_file_path_backup):\n","  # Read the content of the back-up file\n","  with open(main_file_path_backup, 'r') as file:\n","      lines = file.readlines()\n","else:\n","  # Read the content of the original file\n","  with open(main_file_path, 'r') as file:\n","      lines = file.readlines()\n","  # Write the content to the back-up file\n","  with open(main_file_path_backup, 'w') as file:\n","      file.writelines(lines)\n","\n","# Insert the new lines at the desired location (from bottom to top)\n","lines.insert(23, new_line2)\n","lines.insert(8, new_line1)\n","\n","# Write the modified content back to the file\n","with open(main_file_path, 'w') as file:\n","    file.writelines(lines)\n","\n","print(f\"Option file successfully updated in {main_file_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1pbeq-3Jt7Ik","executionInfo":{"status":"ok","timestamp":1716053077604,"user_tz":-120,"elapsed":210,"user":{"displayName":"Giancarlo Cuticchia","userId":"17105111831955175026"}},"outputId":"d3789c92-81af-4593-e09d-7da76806a842"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Option file successfully updated in /content/EDSR-PyTorch/src/main.py\n"]}]},{"cell_type":"markdown","source":["## 3.3 Pass the arguments to the command on the terminal for a training session"],"metadata":{"id":"NfNcxkjVvHPQ"}},{"cell_type":"markdown","source":["For example, if we want to perform a training session with by freezing all the layers except the tail, we can run a command on the terminal like the following:"],"metadata":{"id":"8PB1RE1wvQCU"}},{"cell_type":"code","source":["# Command to train the model (from the src folder)\n","!python main.py --template EDSR_custom --param_to_freeze sub_mean+add_mean+head+body --body_to_freeze \"0-32\" --print_frozen_param --save_models --chop"],"metadata":{"id":"FbFrfH5Gvcqt"},"execution_count":null,"outputs":[]}]}