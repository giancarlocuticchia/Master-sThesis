{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPfWv79gO4xZ9Om9NlAnIWW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 0. Directories"],"metadata":{"id":"mrVxfN50_6eh"}},{"cell_type":"markdown","source":["We are going to place our datasets in a folder named \"images\":"],"metadata":{"id":"ahF6uFrOAB3O"}},{"cell_type":"code","source":["import os\n","\n","dir_base = os.getcwd()                            # Base directory\n","dir_images = os.path.join(dir_base, 'images')     # ./images"],"metadata":{"id":"8m2kiq7h_8xt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. Making the general dataset (TCIA)"],"metadata":{"id":"FOJjrsX2-_JE"}},{"cell_type":"markdown","source":["To make this dataset, we used a total of 35 histopathological High-Resolution (HR) images from The Cancer Imaging Archive (TCIA). These images are shown in the following table:"],"metadata":{"id":"aVXFNgv2_KVb"}},{"cell_type":"markdown","source":["| **Collection** | **Location** | **Data Format** | **Magnification** | **Number of Images** | **Size (GB)** | **Images used**                                                                                                            |\n","|:--------------:|:------------:|:---------------:|:-----------------:|:--------------------:|:-------------:|:--------------------------------------------------------------------------------------------------------------------------:|\n","| CMB-MML        | Blood, Bone  | SVS             | 20 or 40          | 2                    | 0.29          | MSB-04030-12-02 <br> MSB-04030-12-03                                                                                           |\n","| CPTAC-GBM      | Brain        | SVS             | 20 or 40          | 508                  | 87            | C3L-00016-21 <br> C3N-00661-21 <br> C3N-04693-21                                                                                   |\n","| CPTAC-BRCA     | Breast       | SVS             | 20 or 40          | 642                  | 113.29        | 01BR001-0684a407-f446-486d-9160-b483cb <br>  11BR003-2dc74c29-2e89-4600-80bf-1e3637 <br>  22BR001-02797e67-5651-4cc8-b815-904900 |\n","| CPTAC-COAD     | Colon        | SVS             | 20 or 40          | 373                  | 66.69         | 01CO001-760f15d2-444c-4deb-b133-62f3ca <br>  11CO003-2e1d9ae2-f8f8-4d9f-aa2d-ca5577 <br>  22CO006-e1cd3d70-132b-452f-ba10-026721 |\n","| CMB-GEC        | Esophagus    | SVS             | 20 or 40          | 3                    | 0.103         | MSB-06857-01-02 <br> MSB-06857-01-07 <br> MSB-06857-01-12                                                                          |\n","| CPTAC-CCRCC    | Kidney       | SVS             | 20 or 40          | 783                  | 190           | C3L-00004-21 <br> C3N-00148-21 <br> C3N-03021-24                                                                                   |\n","| CPTAC-LUAD     | Lung         | SVS             | 20 or 40          | 1139                 | 435           | C3L-00001-21 <br> C3N-00167-21 <br> C3N-02923-24                                                                                   |\n","| CPTAC-OV       | Ovary        | SVS             | 20 or 40          | 222                  | 54.64         | 01OV002-bd8cdc70-3d46-40ae-99c4-90ef77 <br>  13OV003-407c600a-c0ac-41a6-8d87-fd8a3c <br>  20OV005-4113892a-c489-499e-9255-7328ea |\n","| CPTAC-PDA      | Pancreas     | SVS             | 20 or 40          | 557                  | 88            | C3L-00017-21 <br> C3N-00198-21 <br> C3N-04284-23                                                                                   |\n","| CMB-PCA        | Prostate     | SVS             | 20 or 40          | 3                    | 0.582         | MSB-02917-01-02 <br> MSB-03973-01-02 <br> MSB-07483-01-02                                                                          |\n","| CPTAC-CM       | Skin         | SVS             | 20 or 40          | 404                  | 107           | C3L-00275-21 <br> C3N-00179-21 <br> C3N-05624-25                                                                                   |\n","| CPTAC-UCEC     | Uterus       | SVS             | 20 or 40          | 888                  | 154           | C3L-00006-21 <br> C3N-00151-21 <br> C3N-03767-21                                                                                   |\n"],"metadata":{"id":"Lj2sjhYZ9xy5"}},{"cell_type":"markdown","source":["The images can be downloaded from: https://www.cancerimagingarchive.net/histopathology-imaging-on-tcia/"],"metadata":{"id":"6gAyKW7L_bwP"}},{"cell_type":"markdown","source":["We downloaded each image (in SVS format) by following the instructions in TCIA.\n","\n","We placed each image in a corresponding folder for its type of tissue (e.g. Brain or Lung) and we placed these folders inside a folder \"images_svs\" inside of the \"images\" folder.\n","\n","For example, the image \"C3L-00016-21\" would be in ./images/images_svs/Brain/C3L-00016-21.svs"],"metadata":{"id":"83VV4_bH_xSm"}},{"cell_type":"code","source":["images_folder_svs = os.path.join(dir_images, 'images_svs')"],"metadata":{"id":"BiJkREbE9ynS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We also create a directory to place the images in PNG format:"],"metadata":{"id":"ZoFqlCqiBAOo"}},{"cell_type":"code","source":["images_folder_png = os.path.join(dir_images, 'images_png')\n","\n","# If it doesn't exist already, make it\n","if not os.path.exists(images_folder_png):\n","    os.makedirs(images_folder_png, exist_ok=True)\n","    print(f\"{images_folder_png} directory successfully created.\")"],"metadata":{"id":"he91X6JXBCCF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Note:** We will need to use the **OpenSlide library** to read the images in SVS format. We will have to install it in our environment beforehand, and we can do it in Google Colab by doing:"],"metadata":{"id":"LNVxMCQ-Ce0p"}},{"cell_type":"code","source":["try:\n","  import openslide\n","except:\n","  !apt update && apt install -y openslide-tools\n","  !pip install openslide-python\n","  import openslide"],"metadata":{"id":"wfj6_XUECrVJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.1 Functions definitions"],"metadata":{"id":"a0IKVRd0CxnG"}},{"cell_type":"markdown","source":["We defined some functions to handle the images:"],"metadata":{"id":"dzxF3v21C9SU"}},{"cell_type":"code","source":["## Define some useful functions\n","import math\n","\n","# Return closest slice size and number of slices to divide a certain value\n","def closest_slices_to(value, slice_size=2000, tolerance=0.01):\n","  \"\"\"\n","  Given an input \"value\" we want to divide into an integer number of \"slices\"\n","  of a size close (or above) to a \"slice size\", returns the slice size \"slice_size\"\n","  and number of slices \"n_slices\", so the remaining quantity after the slicing\n","  divided by the input value is below the given tolerance, if possible.\n","\n","  This is:\n","  value = n_slices * slice_size + remaining,   where  remaining/value < tolerance\n","\n","  If tolerance can't be reached, it will return the values so remaining/value\n","  would be the smallest possible.\n","  \"\"\"\n","  n_slices = math.floor(value/slice_size)\n","\n","  while True :\n","    remaining = value - n_slices * slice_size\n","    # If tolerance is reached or won't be reached, breaks\n","    if remaining/value < tolerance or remaining < n_slices :\n","      break\n","    # If not, continues\n","    slice_size += math.floor(remaining/n_slices)\n","\n","  return slice_size, n_slices\n","\n","# Return closest (from below) number to multiple of n\n","def closest_multiple_of(value, n):\n","  \"\"\"\n","  For given \"value\" number, returns the multiple of n closest (from below) to \"value\".\n","  \"\"\"\n","  return value // n * n\n","\n","# Given some area dimensions, return slices dimensions in which it could be divided\n","def slicing_function(height, width, slice_size=2000, multiple_of=1, tolerance=0.01,\n","                     keep_proportions=True):\n","  \"\"\"\n","  Given some area of dimensions (height, width), finds the dimensions of slices in\n","  which this area could be divided, for which the bigger dimension of each slice\n","  will be close (from above) to a \"slice size\" while also being a multiple of\n","  some desired number.\n","\n","  The smaller of the dimensions of each slice would try to keep the ratio of the\n","  dimensions of the original area.\n","\n","  If keep_proportions = False, the slice would be a square and both of its dimensions\n","  would be equal.\n","\n","  The initial value for one of the dimensions of the slice (either the width or\n","  the height, whichever is higher) will be equal to slice_size and it will be\n","  gradually adjusted with higher values until the whole corresponding dimension\n","  of the bigger area can be covered with a whole number of slices, leaving outside\n","  the less amount of pixels as possible. This will try to reach at least a desired\n","  value of \"tolerance\", corresponding to the fraction of area that would be left over.\n","\n","  The other dimension of the slice will be determined using the final value of\n","  this dimension.\n","\n","  Will return:\n","      [slice_height,slice_width] - Height and width of the slices\n","      [new_height, new_width]    - Height and width of the area successfully\n","                                   covered by the slices\n","  \"\"\"\n","  # 1. Find the bigger dimension between height and width\n","  big_dim = max(height, width)\n","\n","  # 2. Find closest slice size for bigger dimension\n","  big_slice_size, big_n_slices = closest_slices_to(big_dim,\n","                                                   slice_size=slice_size,\n","                                                   tolerance=tolerance)\n","\n","  # 3. Find corresponding slice size for smaller dimension\n","  if keep_proportions :\n","    small_slice_size = math.floor(min(height, width)/big_dim * big_slice_size)\n","  else :\n","    small_slice_size = big_slice_size\n","\n","  # 4. Round down to closest multiple of multiple_of\n","  big_slice_size = closest_multiple_of(big_slice_size, n=multiple_of)\n","  small_slice_size = closest_multiple_of(small_slice_size, n=multiple_of)\n","\n","  # 5. Get new number of slices\n","  big_n_slices = math.floor(max(height, width)/big_slice_size)\n","  small_n_slices = math.floor(min(height, width)/small_slice_size)\n","\n","  # 6. Get new height and widths to be multiple of slices sizes\n","  if height > width :\n","    new_height = big_slice_size * big_n_slices\n","    new_width = small_slice_size * small_n_slices\n","\n","    slice_height = big_slice_size\n","    slice_width = small_slice_size\n","  else :\n","    new_width = big_slice_size * big_n_slices\n","    new_height = small_slice_size * small_n_slices\n","\n","    slice_width = big_slice_size\n","    slice_height = small_slice_size\n","\n","  # 7. Return slices dimensions and new image dimensions [height, width]\n","  return [slice_height,slice_width], [new_height, new_width]\n","\n","# Function to crop image (numpy array) to given new dimensions\n","def get_image_boundaries_to_crop(height, width, new_height, new_width,\n","                                 alignment_ver=None, alignment_hor=None):\n","  \"\"\"\n","  Given some image dimensions (height, width) and the desired new dimensions\n","  (new_height, new_width), will return the top, left, right and bottom coordinates\n","  of the image to be cropped.\n","\n","  If alignment = \"center\", will crop from the center of the image. Otherwise,\n","  from the top-left of the image for ver-hor respectively.\n","  \"\"\"\n","  # Defining the cropping coordinates\n","  if alignment_hor == \"center\":\n","      left = int((width - new_width) / 2)\n","      right = int((width + new_width) / 2)\n","  else :\n","      left = 0\n","      right = new_width\n","  if alignment_ver == \"center\":\n","      top = int((height - new_height) / 2)\n","      bottom = int((height + new_height) / 2)\n","  else :\n","      top = 0\n","      bottom = new_height\n","\n","  return top, left, right, bottom\n","\n","\n","# Function to crop image (numpy array) with given specifications\n","def cropping_image_with_slices(image, slice_size=2000, tolerance=0.01, multiple_of=1):\n","  \"\"\"\n","  Images are expected to be numpy arrays of shape: (height,width,channels).\n","  \"\"\"\n","  # Get dimensions from the image\n","  height = image.shape[0]\n","  width = image.shape[1]\n","\n","  # Get slices dimensions and new dimensions\n","  [slice_height,slice_width], [new_height, new_width] = \\\n","            slicing_function(height, width, slice_size=slice_size,\n","                             multiple_of=multiple_of, tolerance=tolerance)\n","\n","  # Get image boundaries\n","  top, left, right, bottom = \\\n","      get_image_boundaries_to_crop(height=height, width=width,\n","                                   new_height=new_height, new_width=new_width,\n","                                   alignment=\"center\")\n","\n","  # 7. Return cropped image and slices dimensions [height, width]\n","  return image[top:bottom,left:right,:], [slice_height,slice_width]\n"],"metadata":{"id":"5WaqTAnlC2EA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import os\n","import openslide\n","\n","# Return if the input image is mostly background\n","def check_if_mostly_background(image, background_color=(255, 255, 255),\n","                               tolerance=20, threshold=0.7):\n","  \"\"\"\n","  Takes an image as input and check if pixels are close to certain background color\n","  for a given tolerance (difference in value). Returns True if the fraction of the\n","  image that is close to the background color is greater than or equal to \"threshold\".\n","\n","  Pixels values are expected to be from 0 to 255. Threshold is expected to be\n","  between 0 and 1.\n","\n","  Images are expected to be numpy arrays of shape: (height,width,channels).\n","  \"\"\"\n","  # Create a mask of the background color\n","  lower_bound = np.array([int(max(value - tolerance,0)) for value in background_color],\n","                         dtype=np.uint8)\n","  upper_bound = np.array([int(min(value + tolerance,255)) for value in background_color],\n","                         dtype=np.uint8)\n","  background_mask = cv2.inRange(image, lower_bound, upper_bound)\n","\n","  # Calculate the proportion of background pixels\n","  height, width, _ = image.shape\n","  background_proportion = cv2.countNonZero(background_mask) / (height * width)\n","\n","  # Returns True if image is mostly background\n","  return background_proportion >= threshold\n","\n","# Slice SVS into smaller PNGs tiles or patches, excluding background\n","def slice_SVS_to_PNGs(image_path, export_folder, image_name=\"image\",\n","                      level=0, magnification=20.0,\n","                      tile_size=2000, scale=1, tolerance=0.01,\n","                      background_color1=(255, 255, 255),\n","                      bk_tolerance1=10, bk_threshold1=0.7,\n","                      background_color2=(0, 0, 0),\n","                      bk_tolerance2=0, bk_threshold2=1.0):\n","  \"\"\"\n","  Load a SVS image from image_path and slice it according to the specifications,\n","  exporting the slices in PNG format to export_folder under image_name.\n","\n","  Slices would be of at least one of its dimensions equal or higher than\n","  tile_size (for a given tolerance), and the other dimension following the\n","  original image proportions, if possible. Both dimensions would be an integer\n","  value multiple of \"scale\".\n","\n","  Slices of the image that are mostly background will be discarded, for a given\n","  background_color, a bk_tolerance (value from 0 to 255) and a bk_threshold\n","  (fraction from 0 to 1 of the slice that is background that is acceptable).\n","  Two colors of background can be provided.\n","  \"\"\"\n","  # Load slide\n","  slide = openslide.OpenSlide(image_path)\n","\n","  # Get information from the image slide\n","  (width, height) = slide.level_dimensions[level]\n","  ApparentMagnification = int(slide.properties[\"aperio.AppMag\"])\n","\n","  # Define some quantities\n","  MagnificationRatio = max(ApparentMagnification/magnification, 1.0)  # In case \"magnification\" would be bigger than the AppMag\n","\n","  # Divide region into slices\n","  slice_size = int(tile_size * MagnificationRatio)   # If this MagRatio is bigger than 1, we will reduce the image tiles size later\n","\n","  [slice_height,slice_width], [new_height, new_width] = \\\n","            slicing_function(height, width, slice_size=slice_size,\n","                             multiple_of=int(scale * MagnificationRatio),\n","                             tolerance=tolerance,keep_proportions=False)\n","\n","  # Get starting positions to crop the whole image\n","  top, left, right, bottom = \\\n","      get_image_boundaries_to_crop(height=height, width=width,\n","                                   new_height=new_height, new_width=new_width,\n","                                   alignment_hor=\"center\",alignment_ver=\"center\")\n","\n","  # Read the whole image by regions and export them\n","  rows = int(new_height/slice_height)\n","  columns = int(new_width/slice_width)\n","  image_counter=1\n","  for row in range(rows):\n","    for column in range(columns):\n","      region = slide.read_region((left + column * slice_width, top + row * slice_height),\n","                                 level,\n","                                 (slice_width, slice_height))\n","\n","      # Transform to numpy array\n","      image = np.array(region)\n","      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)    # Color correction to RGB\n","\n","      # Resize image if necessary\n","      if MagnificationRatio > 1.0 :\n","        scale_down_factor = 1 / MagnificationRatio\n","        image = cv2.resize(image, None, fx=scale_down_factor, fy=scale_down_factor,\n","                          interpolation= cv2.INTER_AREA)   # INTER_AREA is better for downscaling than INTER_CUBIC\n","\n","      # Discard background tiles and save the others\n","      # Check if mostly white\n","      if not check_if_mostly_background(image, background_color=background_color1,\n","                                        tolerance=bk_tolerance1,\n","                                        threshold=bk_threshold1):\n","        # Check if mostly black or dark gray\n","        if not check_if_mostly_background(image, background_color=background_color2,\n","                                        tolerance=bk_tolerance2,\n","                                        threshold=bk_threshold2):\n","          # If not background, export image\n","          image_number = f\"{image_counter:0{len(str(rows * columns))}d}\"    # This will format the numbers like 0016 when applicable\n","          image_counter += 1\n","          image_filename = str(image_name + \"_x\" + str(int(magnification)) + \"_\" + image_number + \".png\")\n","          export_path = os.path.join(export_folder,image_filename)\n","          cv2.imwrite(export_path, image)\n","\n","  return\n","\n"],"metadata":{"id":"qRL16vZcDEgC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.2 Preparing the HR images (slice the SVS images into PNG patches)"],"metadata":{"id":"ailA95yvDQri"}},{"cell_type":"markdown","source":["We are going to load the SVS images in their 20x magnification. Given these images are quite big in size (dimensions of 20,000 px to 50,000 px per side, on average), we will slice them in patches of around 2,000 px per side.\n","\n","We will also use our function check_if_mostly_background() to discard patches that are mostly background (i.e. either mostly white or mostly black), because the background can be a huge portion of these images, with the parameters:\n","\n","* background_color1=(225, 225, 225)       (near white)\n","* background_color2=(30, 30, 30)          (near black)\n","* tolerance = 30\n","* threshold = 0.75\n","\n","So if a patch is at least 75% of a color within a 30 value tolerance from the colors above, it was discarded. All other patches were saved in the PNG folder we previously created.\n","\n"],"metadata":{"id":"3BFGI28wDTnz"}},{"cell_type":"code","source":["# Count total number of svs images\n","number_of_svs_images = 0\n","for folder, _, images_svs_list in os.walk(images_folder_svs):\n","  number_of_svs_images += len(images_svs_list)\n","\n","# Export all PNG images to the same folder (ignore subfolders)\n","export_folder = images_folder_png\n","if not os.path.exists(export_folder):\n","  os.makedirs(export_folder, exist_ok=True)\n","\n","# Iterate over the SVS images and slice them\n","current_img_number = 1\n","for folder, _, images_svs_list in os.walk(images_folder_svs):\n","  # Go over each SVS image on each folder\n","  for image in images_svs_list:\n","    image_path = os.path.join(images_folder_svs, folder, image)\n","\n","    # Prepare image name and folder\n","    image_name = image.split(\".svs\")[0]\n","    folder_name = folder.split(os.path.sep)[-1]\n","\n","    # Slice images in images_svs folder\n","    print(f\"Image {folder_name}/{image} is being sliced... ({current_img_number}/{number_of_svs_images})\")\n","    slice_SVS_to_PNGs(image_path=image_path, export_folder=export_folder,\n","                      image_name=image_name,\n","                      level=0, magnification=20.0,\n","                      tile_size=2000, scale=4, tolerance=0.005,\n","                      background_color1=(225, 225, 225),\n","                      bk_tolerance1=30, bk_threshold1=0.75,\n","                      background_color2=(30, 30, 30),\n","                      bk_tolerance2=30, bk_threshold2=0.75)\n","    print(f\"{image_name} from {image_path} to {export_folder}\")\n","    print(f\"All PNG slices of {folder_name}/{image} has been exported to {export_folder}.\")\n","    current_img_number += 1"],"metadata":{"id":"q9E9hie8DXTl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can make a .zip file with the PNG folder by running:"],"metadata":{"id":"GRJuC6BDFKoR"}},{"cell_type":"code","source":["!zip -r images_png.zip \"images/images_png/\""],"metadata":{"id":"zhUPP1YJFPmp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["If the .zip file would be too big to handle, we can split it in smaller pieces (e.g. 6 GB) by running:"],"metadata":{"id":"_rYmAxITFR7l"}},{"cell_type":"code","source":["!zip images_png.zip --out images_png_part.zip -s 6g"],"metadata":{"id":"-3nATdx4FRRN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.3 Preparing the LR images (downscaling the HR images)"],"metadata":{"id":"KX6TmQBfFjtQ"}},{"cell_type":"markdown","source":["Given we are interest in EDSR x4, we will need to downscale by a factor of 4 the HR images to get our LR images. We do it with the cv2 library from OpenCV, by using the resize() function with INTER_AREA interpolation.\n","\n","The LR images would go to a \"images_png_x4\" folder (i.e. ./images/images_png_x4 )\n","\n","By following the requirements of our training code, each LR images downscaled by a factor of 4 will have the same name as the HR images with \"_x4\" at the end.\n","\n","For example, a HR image named \"image06.png\" will have a corresponding LR image named \"image06_x4.png\"."],"metadata":{"id":"maWquRiRF7nm"}},{"cell_type":"code","source":["import cv2\n","\n","def downscale_and_save_image(image_path, export_path, scale=1):\n","  # Read the image\n","  image = cv2.imread(image_path)\n","\n","  # Downscale image with bicubic algorithm\n","  image = cv2.resize(image, None, fx=1/scale, fy=1/scale,\n","                     interpolation= cv2.INTER_AREA)        #cv2.INTER_CUBIC for bicubic was giving poor results\n","\n","  # Save image\n","  cv2.imwrite(export_path, image)\n","  return\n","\n","\n","# Export all PNG images to the same folder (ignore subfolders)\n","export_folder = os.path.join(dir_images, \"images_png_x4\")\n","if not os.path.exists(export_folder):\n","  os.makedirs(export_folder, exist_ok=True)\n","\n","# Iterate over the PNG images and downscale them\n","scale = 4\n","number_of_folders = 0\n","current_folder_number = 1\n","for folder, folder_list, images_png_list in os.walk(images_folder_png):\n","  # Count number of folders\n","  if number_of_folders == 0 :\n","    number_of_folders = len(folder_list)\n","\n","  # Go over each PNG image on each folder\n","  print(f\"Images on {folder} are being downscaled... ({current_folder_number}/{number_of_folders})\")\n","  for image in images_png_list:\n","    image_path = os.path.join(images_folder_png, folder, image)\n","\n","    # Prepare image name and export path\n","    image_name = image.split(\".png\")[0]\n","    image_filename = str(image_name + \"_x4.png\")\n","    export_path = os.path.join(export_folder,image_filename)\n","\n","    # Downscale and save the images\n","    downscale_and_save_image(image_path=image_path, export_path=export_path,\n","                             scale=scale)\n","\n","  print(f\"All PNG images on {folder} has been downscaled and saved to {export_folder}.\")\n","  current_folder_number += 1"],"metadata":{"id":"vzFm10ECFrtB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can make a .zip file with the folder with the LR images by running:"],"metadata":{"id":"_z2PZSR3GyOC"}},{"cell_type":"code","source":["!zip -r images_png_x4.zip \"images/images_png_x4/\""],"metadata":{"id":"EgqbjgncGyeH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["And again, we can split the .zip file into smaller pieces (e.g. 6 GB) by running:"],"metadata":{"id":"B9Oyjeb5G-jy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!zip images_png_x4.zip --out images_png_x4_part.zip -s 6g"],"metadata":{"id":"0hmacAKEG-JQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.4 Final folder structure"],"metadata":{"id":"eTKEIr5QHJcZ"}},{"cell_type":"markdown","source":["Given we want to use these images to train the EDSR x4 model, we need to prepare them in a folder with a particular structure.\n","\n","If we are going to use our custom.py module, we need to make a folder named \"Custom\".\n","\n","Inside such folder, we will create 2 folders: one named \"HR\" and one named \"LR_bicubic\".\n","\n","Inside the HR folder, we will place the images from \"images_png\".\n","\n","Inside the LR_bicubic folder, we will create a folder named \"X4\". Inside the X4 folder, we will place the images from \"images_png_x4\".\n","\n","Given this is our general dataset, we can place the \"Custom\" folder inside a dedicated folder \"image-data-general\".\n","\n","We should end up having a dataset that would look like:"],"metadata":{"id":"WgPzoXP0HOjJ"}},{"cell_type":"markdown","source":["* image-data-general\n","  * Custom\n","    * HR\n","      * tcia_image0001.png\n","      * ...\n","      * tcia_image2500.png\n","    * LR_bicubic\n","      * X4\n","        * tcia_image0001_x4.png\n","        * ...\n","        * tcia_image2500_x4.png"],"metadata":{"id":"RgNZRWamJRZ8"}},{"cell_type":"markdown","source":["# 2. Making the dedicated dataset (Humanitas)"],"metadata":{"id":"af79ccrAJoR3"}},{"cell_type":"markdown","source":["Given we make our previously dataset in its own folder, we will prepare a dedicated folder for this dataset as well. We will then make a folder \"image-data-dedicated\" inside our \"images\" folder, and create the \"Custom\" folder inside."],"metadata":{"id":"oMGkkai-PV2U"}},{"cell_type":"code","source":["import os\n","\n","dir_custom = os.path.join(dir_images,\"image-data-dedicated\", \"Custom\")    # ./images/image-data-dedicated/Custom\n","if not os.path.exists(dir_custom):\n","  os.makedirs(dir_custom, exist_ok=True)"],"metadata":{"id":"eG96WbkTPVS1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.1 Preparing the HR images"],"metadata":{"id":"a0jiWk9bJsTD"}},{"cell_type":"markdown","source":["The patches provided to us from the Humanitas Research Institute were already in PNG format, with square dimensions of 256 px per side.\n","\n","Given that, we didn't need to perform any other action on them, rather than placing them inside of the corresponding HR folder of the dataset.\n","\n","**Note:** Even if images are in PNG format, they could be in either RGB or RGBA mode. Our images were in RGBA mode, and we need to convert them in RGB, in order to avoid conflicts during our training. A way to do it is the following:"],"metadata":{"id":"F-O_SOHmMaxM"}},{"cell_type":"code","source":["from PIL import Image\n","\n","img_path = \"/content/img.png\"\n","img = Image.Open(img_path)\n","img_rgb = img.convert('RGB')\n","\n","new_img_rgb_path = \"/content/img_rgb.png\"\n","img_rgb.save(new_img_rgb_path)"],"metadata":{"id":"2aaRRobHN8Gz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Alternatively, given that we got access to the Humanitas patches on a server (located in a path stored in the variable \"dir_patches\" that we have below), we decided to copy and convert the HR images directly with the code below, by using cv2:"],"metadata":{"id":"JY5faDZZPI2h"}},{"cell_type":"code","source":["import os\n","import cv2\n","\n","# Create the HR folder\n","dir_hr = os.path.join(dir_custom, \"HR\")    # ./images/image-data-dedicated/Custom/HR\n","if not os.path.exists(dir_hr):\n","  os.makedirs(dir_hr, exist_ok=True)\n","\n","# Function to copy images from one folder to another using cv2\n","def copy_images_with_cv2(source_dir, destination_dir, verbose=False):\n","    # Create destination directory if it doesn't exist\n","    if not os.path.exists(destination_dir):\n","        os.makedirs(destination_dir)\n","\n","    # Iterate over files in the source directory\n","    for file_name in os.listdir(source_dir):\n","        source_file = os.path.join(source_dir, file_name)\n","        destination_file = os.path.join(destination_dir, file_name)\n","        # Load image with cv2\n","        image = cv2.imread(source_file)\n","        # Save image with cv2\n","        cv2.imwrite(destination_file, image)\n","        if verbose :\n","            print(f\"Copied {file_name} to {destination_dir}\")\n","\n","\n","# Copy HR images from \"PatchesHumanitas_256x256_10x\" to HR\n","source_dir = dir_patches\n","destination_dir = dir_hr\n","\n","#copy_files(source_dir, destination_dir, print=False)\n","copy_images_with_cv2(source_dir, destination_dir, verbose=False)\n","\n","print(f\"All images from {source_dir} were copied to {destination_dir}\")"],"metadata":{"id":"nVmM9M2jPJJq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.2 Preparing the LR images"],"metadata":{"id":"82JlKBpeUhar"}},{"cell_type":"markdown","source":["We created the LR_bicubic/X4 folder and placed the LR images inside (downscaled from the HR images by a factor 4), with the appropiate name, in the same way we did with general dataset.\n","\n","We can do this with the code below:"],"metadata":{"id":"lKBtvnyvUq1K"}},{"cell_type":"code","source":["import os\n","import cv2\n","\n","# Create the LR/X4 folder\n","dir_lr = os.path.join(dir_custom, \"LR_bicubic\")    # ./images/image-data-dedicated/Custom/LR_bicubic\n","dir_lr_x4 = os.path.join(dir_lr, \"X4\")             # ./images/image-data-dedicated/Custom/LR_bicubic/X4\n","if not os.path.exists(dir_lr_x4):\n","  os.makedirs(dir_lr_x4, exist_ok=True)\n","\n","\n","# Function to downscale one HR image and store it as its LR counterpart\n","def downscale_and_save_image(image_path, export_path, scale=1):\n","  # Read the image\n","  image = cv2.imread(image_path)\n","\n","  # Downscale image\n","  image = cv2.resize(image, None, fx=1/scale, fy=1/scale,\n","                     interpolation= cv2.INTER_AREA)        #cv2.INTER_CUBIC for bicubic was giving poor results\n","\n","  # Save image\n","  cv2.imwrite(export_path, image)\n","  return\n","\n","\n","# Iterate over the HR images and downscale them\n","scale = 4\n","counter = 0\n","print_saves = True\n","print_each = 2000\n","\n","for file_name in os.listdir(dir_hr):\n","    if file_name.lower().endswith('.png'):\n","        #Prepare image name\n","        image_name = file_name.split(\".png\")[0]\n","        image_filename = str(image_name + \"_x4.png\")\n","\n","        #Get path\n","        image_path = os.path.join(dir_hr, file_name)\n","        export_path = os.path.join(dir_lr_x4, image_filename)\n","\n","        # Downscale and save the images\n","        downscale_and_save_image(image_path=image_path, export_path=export_path, scale=scale)\n","\n","        counter+=1\n","\n","        # Print\n","        if print_saves and counter % print_each == 0 :\n","            print(f\"A total of: {counter} images have been downscaled and saved.\")\n","\n","print(f\"All PNG images on {dir_hr} has been 4x downscaled and saved in {dir_lr_x4}.\")"],"metadata":{"id":"r3ZTIYggUrEt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.3 Checking the images"],"metadata":{"id":"3Sxa7s3DVRYu"}},{"cell_type":"markdown","source":["Given the dataset is conformed of a big number of images (32,261), we defined the functions below in order to check pertinent information about the HR and LR folders with images.\n","\n","By running the appropiate code, we got that:\n","\n","* For the HR folder:\n","  * Number of files: 32261\n","  * Folder size: 4.07 GB\n","  * Different file extensions within the directory: ['.png']\n","  * Dimensions count len: 1\n","  * (width,height): (256, 256), Count: 32261\n","\n","* For the LR_bicubic/X4 folder:\n","  * Number of files: 32261\n","  * Folder size: 294.92 MB\n","  * Different file extensions within the directory: ['.png']\n","  * Dimensions count len: 1\n","  * (width,height): (64, 64), Count: 32261\n","\n","  Meaning we had all corresponding 32,261 images on each folder, all images are in .png format, and they are all of the same dimension (dimensions count length = 1), where for the HR the dimensions are 256 x 256 px, and for the LR they are 64 x 64 px, with 4.07 GB and 294.92 MB of folder size, respectively."],"metadata":{"id":"wXJU2rnWVn8z"}},{"cell_type":"code","source":["import os\n","from PIL import Image\n","\n","def get_dir_stats(dir_path):\n","    total_files = 0\n","    total_size = 0\n","\n","    # Walk through the directory tree\n","    for root, dirs, files in os.walk(dir_path):\n","        # Count files\n","        total_files += len(files)\n","        # Calculate total size\n","        for file in files:\n","            file_path = os.path.join(root, file)\n","            total_size += os.path.getsize(file_path)\n","\n","    # Convert size to human-readable format\n","    total_size_str = _format_size(total_size)\n","\n","    return total_files, total_size_str\n","\n","def _format_size(size_bytes):\n","    # Convert bytes to appropriate unit (KB, MB, GB, etc.)\n","    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:\n","        if size_bytes < 1024.0:\n","            return f\"{size_bytes:.2f} {unit}\"\n","        size_bytes /= 1024.0\n","\n","def get_unique_file_extensions(dir_path):\n","    extensions = []\n","\n","    # Walk through the directory tree\n","    for root, dirs, files in os.walk(dir_path):\n","        # Extract file extensions\n","        for file in files:\n","            _, extension = os.path.splitext(file)\n","            if extension.lower() not in extensions:\n","                extensions.append(extension.lower())\n","\n","    return extensions\n","\n","def get_unique_dimensions_with_count(dir_path):\n","    dimensions_count = {}\n","\n","    # Walk through the directory tree\n","    for root, dirs, files in os.walk(dir_path):\n","        # Iterate over PNG files\n","        for file in files:\n","            if file.lower().endswith('.png'):\n","                file_path = os.path.join(root, file)\n","                try:\n","                    # Open the image and get its dimensions\n","                    with Image.open(file_path) as img:\n","                        width, height = img.size\n","                        dimensions = (width, height)\n","                        # Update dimensions count\n","                        if dimensions in dimensions_count:\n","                            dimensions_count[dimensions] += 1\n","                        else:\n","                            dimensions_count[dimensions] = 1\n","                except Exception as e:\n","                    print(f\"Error processing {file}: {e}\")\n","\n","    return dimensions_count"],"metadata":{"id":"NJLnErikVgkG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Checking the contents of the HR folder\n","folder_to_check = dir_hr\n","\n","# Number of files and folder size\n","num_files, dir_size = get_dir_stats(folder_to_check)\n","print(f\"Number of files: {num_files}\")\n","print(f\"Folder size: {dir_size}\")\n","\n","# File extensions present in the folder\n","extensions = get_unique_file_extensions(folder_to_check)\n","print(f\"Different file extensions within the directory: {extensions}\")\n","\n","# Dimensions of the images presents in the folder\n","dimensions_count = get_unique_dimensions_with_count(folder_to_check)\n","print(f\"Dimensions count len: {len(dimensions_count)}\")\n","for dimensions, count in dimensions_count.items():\n","    print(f\"(width,height): {dimensions}, Count: {count}\")"],"metadata":{"id":"aq-dqTZ9VbaI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Checking the contents of the LR/X4 folder\n","folder_to_check = dir_lr_x4\n","\n","# Number of files and folder size\n","num_files, dir_size = get_dir_stats(folder_to_check)\n","print(f\"Number of files: {num_files}\")\n","print(f\"Folder size: {dir_size}\")\n","\n","# File extensions present in the folder\n","extensions = get_unique_file_extensions(folder_to_check)\n","print(f\"Different file extensions within the directory: {extensions}\")\n","\n","# Dimensions of the images presents in the folder\n","dimensions_count = get_unique_dimensions_with_count(folder_to_check)\n","print(f\"Dimensions count len: {len(dimensions_count)}\")\n","for dimensions, count in dimensions_count.items():\n","    print(f\"(width,height): {dimensions}, Count: {count}\")"],"metadata":{"id":"E4O92gCcVY5l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.4 Final folder structure"],"metadata":{"id":"nmw03XhmW4Zv"}},{"cell_type":"markdown","source":["If everything went alright, and all images are properly placed, we should have a dataset with the expected structure:"],"metadata":{"id":"-1ysBtaWW6hk"}},{"cell_type":"markdown","source":["* image-data-dedicated\n","  * Custom\n","    * HR\n","      * humanitas_image00001.png\n","      * ...\n","      * humanitas_image32261.png\n","    * LR_bicubic\n","      * X4\n","        * humanitas_image00001_x4.png\n","        * ...\n","        * humanitas_image32261_x4.png"],"metadata":{"id":"dxDs_MMcXCxn"}}]}